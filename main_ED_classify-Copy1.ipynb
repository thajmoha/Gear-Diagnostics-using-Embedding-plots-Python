{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embdeded Dimension Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Dropbox (new)\\Dropbox (VCADS)\\turki Mustafa’s files\\Home\\1Work Documentation-Projects\\2In progress Papers\\Embedded dimention Journal paper\\MATLAB code\\Gearbox data\\ch5_embedded\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Admin\\Dropbox (new)\\Dropbox (VCADS)\\turki Mustafa’s files\\Home\\1Work Documentation-Projects\\2In progress Papers\\Embedded dimention Journal paper\\MATLAB code\\Gearbox data\\ch5_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Dropbox (VCADS)\\1Work Documentation-Projects\\2In progress Papers\\Embedded dimention Journal paper\\MATLAB code\\Gearbox data\\ch5_embedded\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\Admin\\Dropbox (VCADS)\\1Work Documentation-Projects\\2In progress Papers\\Embedded dimention Journal paper\\MATLAB code\\Gearbox data\\ch5_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_reader(filename):\n",
    "    input_mat = scipy.io.loadmat(filename)\n",
    "    E2 = input_mat['E2_S1']\n",
    "    A = E2.tolist()\n",
    "    E2 = np.asarray(A)\n",
    "    del A\n",
    "\n",
    "    E2 = E2.reshape((E2.shape[0],E2.shape[1],E2.shape[3]))\n",
    "    \n",
    "    A = E2[:,0,:]\n",
    "    A = A.reshape(1,A.shape[0],A.shape[1])\n",
    "\n",
    "    for isample in np.arange(1,E2.shape[1]):\n",
    "        B = E2[:,isample,:]\n",
    "        B = B.reshape(1,B.shape[0],B.shape[1])\n",
    "        A = np.concatenate((A,B))\n",
    "    \n",
    "    return A    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'Healthy_data_1win_15subwin.mat'\n",
    "# filename = 'singlecrack_data_1win_15subwin.mat'\n",
    "# filename = 'Multicrack_data_1win_15subwin.mat'\n",
    "Filenames = ['Healthy_data_1win_15subwin.mat','singlecrack_data_1win_15subwin.mat','Multicrack_data_1win_15subwin.mat']\n",
    "for ifile in range(0,len(Filenames)):\n",
    "    if ifile == 0:\n",
    "        Feat = feat_reader(Filenames[ifile])\n",
    "        N = Feat.shape[0]\n",
    "        Target = ifile*np.ones((N,1))\n",
    "    else:\n",
    "        A = feat_reader(Filenames[ifile])\n",
    "        Feat = np.concatenate((Feat,A))\n",
    "        N = A.shape[0]\n",
    "        Target = np.concatenate((Target,ifile*np.ones((N,1))))\n",
    "        \n",
    "# B1 = feat_reader(Filenames[0])\n",
    "# B2 = feat_reader(Filenames[1])\n",
    "# B3 = feat_reader(Filenames[2])\n",
    "# B = np.concatenate((B1,B2,B3))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90454714, 0.79565243, 0.63640272, 0.64143227, 0.73813584,\n",
       "       0.80067739, 0.87617896, 0.94483985, 0.96508699, 0.98740422])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feat[196+12,10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Feat, Target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = Feat\n",
    "# scalers = {}\n",
    "# for i in range(Feat.shape[1]):\n",
    "#     scalers[i] = StandardScaler()\n",
    "#     X_train[:, i, :] = scalers[i].fit_transform(Feat[:, i, :]) \n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, layers\n",
    "from keras.callbacks import ModelCheckpoint # it si important not only to save the final results but every result at every iteration in case if the program crashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = 1\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_num)\n",
    "\n",
    "import random\n",
    "random.seed(seed_num)\n",
    "\n",
    "seed_num = 1\n",
    "from numpy.random import seed\n",
    "seed(seed_num)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = layers.Input(shape = (Feat.shape[1:]),name = 'input1')\n",
    "x = layers.Flatten()(input1)\n",
    "x = layers.Dense(units = 20,activation = 'relu')(x)\n",
    "# x = layers.Dense(units = 5,activation = 'relu')(x)\n",
    "output1 = layers.Dense(3,activation = 'softmax',name = 'output1')(x)\n",
    "\n",
    "model = Model(inputs = {'input1':input1},outputs = {'output1':output1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          [(None, 15, 10)]          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 20)                3020      \n",
      "_________________________________________________________________\n",
      "output1 (Dense)              (None, 3)                 63        \n",
      "=================================================================\n",
      "Total params: 3,083\n",
      "Trainable params: 3,083\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176 samples, validate on 20 samples\n",
      "Epoch 1/1000\n",
      "176/176 [==============================] - 0s 2ms/sample - loss: 1.1291 - accuracy: 0.3807 - val_loss: 1.0256 - val_accuracy: 0.6500\n",
      "Epoch 2/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 1.0588 - accuracy: 0.3466 - val_loss: 1.0396 - val_accuracy: 0.4500\n",
      "Epoch 3/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 1.0332 - accuracy: 0.5000 - val_loss: 1.0601 - val_accuracy: 0.5000\n",
      "Epoch 4/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 1.0051 - accuracy: 0.5455 - val_loss: 0.9717 - val_accuracy: 0.6000\n",
      "Epoch 5/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.9739 - accuracy: 0.5966 - val_loss: 0.9578 - val_accuracy: 0.6500\n",
      "Epoch 6/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.9477 - accuracy: 0.7045 - val_loss: 0.9455 - val_accuracy: 0.7500\n",
      "Epoch 7/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.9217 - accuracy: 0.8295 - val_loss: 0.9355 - val_accuracy: 0.6000\n",
      "Epoch 8/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.8937 - accuracy: 0.7216 - val_loss: 0.8930 - val_accuracy: 0.7000\n",
      "Epoch 9/1000\n",
      "176/176 [==============================] - 0s 364us/sample - loss: 0.8686 - accuracy: 0.7273 - val_loss: 0.8889 - val_accuracy: 0.7000\n",
      "Epoch 10/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.8429 - accuracy: 0.7841 - val_loss: 0.8797 - val_accuracy: 0.5500\n",
      "Epoch 11/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.8193 - accuracy: 0.8580 - val_loss: 0.8485 - val_accuracy: 0.6500\n",
      "Epoch 12/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.7904 - accuracy: 0.8239 - val_loss: 0.8145 - val_accuracy: 0.8000\n",
      "Epoch 13/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.7708 - accuracy: 0.8239 - val_loss: 0.8141 - val_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.7418 - accuracy: 0.7614 - val_loss: 0.7704 - val_accuracy: 0.8000\n",
      "Epoch 15/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.7232 - accuracy: 0.7216 - val_loss: 0.7602 - val_accuracy: 0.7500\n",
      "Epoch 16/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.6931 - accuracy: 0.8750 - val_loss: 0.7829 - val_accuracy: 0.7000\n",
      "Epoch 17/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.6750 - accuracy: 0.8239 - val_loss: 0.7393 - val_accuracy: 0.7000\n",
      "Epoch 18/1000\n",
      "176/176 [==============================] - 0s 477us/sample - loss: 0.6478 - accuracy: 0.8693 - val_loss: 0.7016 - val_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.6279 - accuracy: 0.8523 - val_loss: 0.6937 - val_accuracy: 0.7000\n",
      "Epoch 20/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.6086 - accuracy: 0.8920 - val_loss: 0.6937 - val_accuracy: 0.7500\n",
      "Epoch 21/1000\n",
      "176/176 [==============================] - 0s 477us/sample - loss: 0.5930 - accuracy: 0.8693 - val_loss: 0.6776 - val_accuracy: 0.6500\n",
      "Epoch 22/1000\n",
      "176/176 [==============================] - 0s 568us/sample - loss: 0.5839 - accuracy: 0.7614 - val_loss: 0.6189 - val_accuracy: 0.8000\n",
      "Epoch 23/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.5534 - accuracy: 0.8523 - val_loss: 0.6744 - val_accuracy: 0.7000\n",
      "Epoch 24/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.5442 - accuracy: 0.8295 - val_loss: 0.6788 - val_accuracy: 0.6500\n",
      "Epoch 25/1000\n",
      "176/176 [==============================] - 0s 568us/sample - loss: 0.5337 - accuracy: 0.8409 - val_loss: 0.5984 - val_accuracy: 0.7000\n",
      "Epoch 26/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.5152 - accuracy: 0.8295 - val_loss: 0.5992 - val_accuracy: 0.7500\n",
      "Epoch 27/1000\n",
      "176/176 [==============================] - 0s 250us/sample - loss: 0.5081 - accuracy: 0.8693 - val_loss: 0.6382 - val_accuracy: 0.7000\n",
      "Epoch 28/1000\n",
      "176/176 [==============================] - 0s 477us/sample - loss: 0.4923 - accuracy: 0.8750 - val_loss: 0.5676 - val_accuracy: 0.7000\n",
      "Epoch 29/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.4797 - accuracy: 0.9091 - val_loss: 0.5904 - val_accuracy: 0.7000\n",
      "Epoch 30/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.4691 - accuracy: 0.8920 - val_loss: 0.5809 - val_accuracy: 0.7500\n",
      "Epoch 31/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.4587 - accuracy: 0.9318 - val_loss: 0.5485 - val_accuracy: 0.7000\n",
      "Epoch 32/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.4474 - accuracy: 0.9148 - val_loss: 0.5602 - val_accuracy: 0.7500\n",
      "Epoch 33/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.4425 - accuracy: 0.8636 - val_loss: 0.5636 - val_accuracy: 0.7000\n",
      "Epoch 34/1000\n",
      "176/176 [==============================] - 0s 545us/sample - loss: 0.4312 - accuracy: 0.8920 - val_loss: 0.5390 - val_accuracy: 0.7000\n",
      "Epoch 35/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.4263 - accuracy: 0.8920 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
      "Epoch 36/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.4221 - accuracy: 0.8750 - val_loss: 0.5069 - val_accuracy: 0.7000\n",
      "Epoch 37/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.4152 - accuracy: 0.8693 - val_loss: 0.5559 - val_accuracy: 0.7000\n",
      "Epoch 38/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.4093 - accuracy: 0.8523 - val_loss: 0.5473 - val_accuracy: 0.7000\n",
      "Epoch 39/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.3966 - accuracy: 0.8864 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
      "Epoch 40/1000\n",
      "176/176 [==============================] - 0s 538us/sample - loss: 0.3929 - accuracy: 0.9318 - val_loss: 0.4926 - val_accuracy: 0.7500\n",
      "Epoch 41/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.3923 - accuracy: 0.9148 - val_loss: 0.5198 - val_accuracy: 0.7000\n",
      "Epoch 42/1000\n",
      "176/176 [==============================] - 0s 500us/sample - loss: 0.3830 - accuracy: 0.9091 - val_loss: 0.4874 - val_accuracy: 0.7500\n",
      "Epoch 43/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.3778 - accuracy: 0.9375 - val_loss: 0.5052 - val_accuracy: 0.7000\n",
      "Epoch 44/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.3718 - accuracy: 0.8920 - val_loss: 0.5111 - val_accuracy: 0.7000\n",
      "Epoch 45/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.3694 - accuracy: 0.8807 - val_loss: 0.5049 - val_accuracy: 0.7000\n",
      "Epoch 46/1000\n",
      "176/176 [==============================] - 0s 477us/sample - loss: 0.3621 - accuracy: 0.8977 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
      "Epoch 47/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.3584 - accuracy: 0.9091 - val_loss: 0.4788 - val_accuracy: 0.7500\n",
      "Epoch 48/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.3567 - accuracy: 0.8977 - val_loss: 0.4914 - val_accuracy: 0.7000\n",
      "Epoch 49/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.3501 - accuracy: 0.9034 - val_loss: 0.4698 - val_accuracy: 0.7500\n",
      "Epoch 50/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.3471 - accuracy: 0.9091 - val_loss: 0.4787 - val_accuracy: 0.7500\n",
      "Epoch 51/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.3425 - accuracy: 0.9205 - val_loss: 0.4633 - val_accuracy: 0.7500\n",
      "Epoch 52/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.3391 - accuracy: 0.9091 - val_loss: 0.4760 - val_accuracy: 0.7500\n",
      "Epoch 53/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.3358 - accuracy: 0.9034 - val_loss: 0.4662 - val_accuracy: 0.7500\n",
      "Epoch 54/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.3349 - accuracy: 0.9318 - val_loss: 0.4501 - val_accuracy: 0.7500\n",
      "Epoch 55/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.3303 - accuracy: 0.9091 - val_loss: 0.4931 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.3259 - accuracy: 0.9034 - val_loss: 0.4497 - val_accuracy: 0.7500\n",
      "Epoch 57/1000\n",
      "176/176 [==============================] - 0s 500us/sample - loss: 0.3291 - accuracy: 0.8977 - val_loss: 0.4427 - val_accuracy: 0.7500\n",
      "Epoch 58/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.3212 - accuracy: 0.9261 - val_loss: 0.4696 - val_accuracy: 0.7000\n",
      "Epoch 59/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.3173 - accuracy: 0.8920 - val_loss: 0.4747 - val_accuracy: 0.7000\n",
      "Epoch 60/1000\n",
      "176/176 [==============================] - 0s 477us/sample - loss: 0.3177 - accuracy: 0.9148 - val_loss: 0.4374 - val_accuracy: 0.7500\n",
      "Epoch 61/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.3131 - accuracy: 0.9034 - val_loss: 0.4556 - val_accuracy: 0.7000\n",
      "Epoch 62/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.3102 - accuracy: 0.9261 - val_loss: 0.4430 - val_accuracy: 0.7500\n",
      "Epoch 63/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.3053 - accuracy: 0.9261 - val_loss: 0.4570 - val_accuracy: 0.7000\n",
      "Epoch 64/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.3043 - accuracy: 0.8920 - val_loss: 0.4744 - val_accuracy: 0.7000\n",
      "Epoch 65/1000\n",
      "176/176 [==============================] - 0s 523us/sample - loss: 0.3017 - accuracy: 0.8864 - val_loss: 0.4373 - val_accuracy: 0.7500\n",
      "Epoch 66/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.2996 - accuracy: 0.9205 - val_loss: 0.4179 - val_accuracy: 0.7500\n",
      "Epoch 67/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2979 - accuracy: 0.9205 - val_loss: 0.4688 - val_accuracy: 0.7000\n",
      "Epoch 68/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2970 - accuracy: 0.8920 - val_loss: 0.4416 - val_accuracy: 0.7500\n",
      "Epoch 69/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2937 - accuracy: 0.9091 - val_loss: 0.4524 - val_accuracy: 0.7000\n",
      "Epoch 70/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2893 - accuracy: 0.9091 - val_loss: 0.4295 - val_accuracy: 0.7500\n",
      "Epoch 71/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2871 - accuracy: 0.9261 - val_loss: 0.4246 - val_accuracy: 0.7500\n",
      "Epoch 72/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.2864 - accuracy: 0.9148 - val_loss: 0.4324 - val_accuracy: 0.7500\n",
      "Epoch 73/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2830 - accuracy: 0.9091 - val_loss: 0.4248 - val_accuracy: 0.7500\n",
      "Epoch 74/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2834 - accuracy: 0.9318 - val_loss: 0.4400 - val_accuracy: 0.7000\n",
      "Epoch 75/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2782 - accuracy: 0.9261 - val_loss: 0.4215 - val_accuracy: 0.7500\n",
      "Epoch 76/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2783 - accuracy: 0.9091 - val_loss: 0.4382 - val_accuracy: 0.7500\n",
      "Epoch 77/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2752 - accuracy: 0.9034 - val_loss: 0.4213 - val_accuracy: 0.7500\n",
      "Epoch 78/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2744 - accuracy: 0.9261 - val_loss: 0.4251 - val_accuracy: 0.7500\n",
      "Epoch 79/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.2730 - accuracy: 0.9034 - val_loss: 0.4447 - val_accuracy: 0.7000\n",
      "Epoch 80/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2713 - accuracy: 0.9091 - val_loss: 0.4182 - val_accuracy: 0.7500\n",
      "Epoch 81/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2711 - accuracy: 0.9318 - val_loss: 0.4233 - val_accuracy: 0.7500\n",
      "Epoch 82/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2704 - accuracy: 0.8920 - val_loss: 0.4499 - val_accuracy: 0.7000\n",
      "Epoch 83/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.2657 - accuracy: 0.9205 - val_loss: 0.4044 - val_accuracy: 0.8000\n",
      "Epoch 84/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2666 - accuracy: 0.9375 - val_loss: 0.4150 - val_accuracy: 0.7500\n",
      "Epoch 85/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2652 - accuracy: 0.9148 - val_loss: 0.4617 - val_accuracy: 0.7000\n",
      "Epoch 86/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2708 - accuracy: 0.9091 - val_loss: 0.4054 - val_accuracy: 0.8000\n",
      "Epoch 87/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2602 - accuracy: 0.9261 - val_loss: 0.4417 - val_accuracy: 0.7000\n",
      "Epoch 88/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2590 - accuracy: 0.9148 - val_loss: 0.4045 - val_accuracy: 0.8000\n",
      "Epoch 89/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2587 - accuracy: 0.9261 - val_loss: 0.4171 - val_accuracy: 0.7500\n",
      "Epoch 90/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2544 - accuracy: 0.9318 - val_loss: 0.4081 - val_accuracy: 0.8000\n",
      "Epoch 91/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2563 - accuracy: 0.9205 - val_loss: 0.4382 - val_accuracy: 0.7000\n",
      "Epoch 92/1000\n",
      "176/176 [==============================] - 0s 364us/sample - loss: 0.2500 - accuracy: 0.9261 - val_loss: 0.3911 - val_accuracy: 0.7500\n",
      "Epoch 93/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.2552 - accuracy: 0.9318 - val_loss: 0.4152 - val_accuracy: 0.7500\n",
      "Epoch 94/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2478 - accuracy: 0.9261 - val_loss: 0.4105 - val_accuracy: 0.8000\n",
      "Epoch 95/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2474 - accuracy: 0.9261 - val_loss: 0.4090 - val_accuracy: 0.8000\n",
      "Epoch 96/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2465 - accuracy: 0.9205 - val_loss: 0.4224 - val_accuracy: 0.7500\n",
      "Epoch 97/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.2457 - accuracy: 0.9091 - val_loss: 0.4151 - val_accuracy: 0.7500\n",
      "Epoch 98/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.2484 - accuracy: 0.9318 - val_loss: 0.3939 - val_accuracy: 0.8000\n",
      "Epoch 99/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2409 - accuracy: 0.9148 - val_loss: 0.4452 - val_accuracy: 0.7000\n",
      "Epoch 100/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2455 - accuracy: 0.9034 - val_loss: 0.4083 - val_accuracy: 0.8000\n",
      "Epoch 101/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2405 - accuracy: 0.9432 - val_loss: 0.3964 - val_accuracy: 0.8000\n",
      "Epoch 102/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2385 - accuracy: 0.9432 - val_loss: 0.4101 - val_accuracy: 0.7500\n",
      "Epoch 103/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2404 - accuracy: 0.9034 - val_loss: 0.4260 - val_accuracy: 0.7000\n",
      "Epoch 104/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.2415 - accuracy: 0.9375 - val_loss: 0.3845 - val_accuracy: 0.8000\n",
      "Epoch 105/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2365 - accuracy: 0.9205 - val_loss: 0.4188 - val_accuracy: 0.7500\n",
      "Epoch 106/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2352 - accuracy: 0.9091 - val_loss: 0.3977 - val_accuracy: 0.8000\n",
      "Epoch 107/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2363 - accuracy: 0.9432 - val_loss: 0.3921 - val_accuracy: 0.8000\n",
      "Epoch 108/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.2417 - accuracy: 0.9148 - val_loss: 0.4181 - val_accuracy: 0.7500\n",
      "Epoch 109/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2331 - accuracy: 0.9205 - val_loss: 0.3849 - val_accuracy: 0.8000\n",
      "Epoch 110/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2308 - accuracy: 0.9318 - val_loss: 0.4117 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2312 - accuracy: 0.9148 - val_loss: 0.4009 - val_accuracy: 0.8000\n",
      "Epoch 112/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2305 - accuracy: 0.9375 - val_loss: 0.3852 - val_accuracy: 0.8000\n",
      "Epoch 113/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2312 - accuracy: 0.9318 - val_loss: 0.4122 - val_accuracy: 0.7500\n",
      "Epoch 114/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2258 - accuracy: 0.9205 - val_loss: 0.3867 - val_accuracy: 0.8000\n",
      "Epoch 115/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2246 - accuracy: 0.9432 - val_loss: 0.3996 - val_accuracy: 0.8000\n",
      "Epoch 116/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2240 - accuracy: 0.9148 - val_loss: 0.3962 - val_accuracy: 0.8000\n",
      "Epoch 117/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2291 - accuracy: 0.9432 - val_loss: 0.3872 - val_accuracy: 0.8000\n",
      "Epoch 118/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2425 - accuracy: 0.8864 - val_loss: 0.4187 - val_accuracy: 0.7500\n",
      "Epoch 119/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.2247 - accuracy: 0.9261 - val_loss: 0.3700 - val_accuracy: 0.7500\n",
      "Epoch 120/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.2198 - accuracy: 0.9432 - val_loss: 0.4180 - val_accuracy: 0.7500\n",
      "Epoch 121/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2367 - accuracy: 0.8920 - val_loss: 0.4447 - val_accuracy: 0.7000\n",
      "Epoch 122/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.2247 - accuracy: 0.9205 - val_loss: 0.3614 - val_accuracy: 0.8000\n",
      "Epoch 123/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2253 - accuracy: 0.9261 - val_loss: 0.4311 - val_accuracy: 0.7000\n",
      "Epoch 124/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2229 - accuracy: 0.9034 - val_loss: 0.3956 - val_accuracy: 0.8000\n",
      "Epoch 125/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2164 - accuracy: 0.9489 - val_loss: 0.3786 - val_accuracy: 0.8000\n",
      "Epoch 126/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.2165 - accuracy: 0.9489 - val_loss: 0.3844 - val_accuracy: 0.8000\n",
      "Epoch 127/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.2135 - accuracy: 0.9432 - val_loss: 0.3801 - val_accuracy: 0.8000\n",
      "Epoch 128/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2132 - accuracy: 0.9432 - val_loss: 0.3902 - val_accuracy: 0.8000\n",
      "Epoch 129/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2127 - accuracy: 0.9432 - val_loss: 0.3829 - val_accuracy: 0.8000\n",
      "Epoch 130/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2106 - accuracy: 0.9318 - val_loss: 0.4018 - val_accuracy: 0.8000\n",
      "Epoch 131/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2105 - accuracy: 0.9261 - val_loss: 0.3707 - val_accuracy: 0.8000\n",
      "Epoch 132/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.2104 - accuracy: 0.9489 - val_loss: 0.3878 - val_accuracy: 0.8000\n",
      "Epoch 133/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2093 - accuracy: 0.9261 - val_loss: 0.3905 - val_accuracy: 0.8000\n",
      "Epoch 134/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2175 - accuracy: 0.9375 - val_loss: 0.3689 - val_accuracy: 0.8000\n",
      "Epoch 135/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2142 - accuracy: 0.9205 - val_loss: 0.4103 - val_accuracy: 0.7500\n",
      "Epoch 136/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.2153 - accuracy: 0.9318 - val_loss: 0.3610 - val_accuracy: 0.8000\n",
      "Epoch 137/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2065 - accuracy: 0.9489 - val_loss: 0.3943 - val_accuracy: 0.8000\n",
      "Epoch 138/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2092 - accuracy: 0.9205 - val_loss: 0.3828 - val_accuracy: 0.8000\n",
      "Epoch 139/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2060 - accuracy: 0.9489 - val_loss: 0.3799 - val_accuracy: 0.8000\n",
      "Epoch 140/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2014 - accuracy: 0.9432 - val_loss: 0.3984 - val_accuracy: 0.8000\n",
      "Epoch 141/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2083 - accuracy: 0.9034 - val_loss: 0.3730 - val_accuracy: 0.8000\n",
      "Epoch 142/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.2078 - accuracy: 0.9489 - val_loss: 0.3556 - val_accuracy: 0.8000\n",
      "Epoch 143/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2042 - accuracy: 0.9261 - val_loss: 0.4236 - val_accuracy: 0.7500\n",
      "Epoch 144/1000\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.84 - 0s 114us/sample - loss: 0.2087 - accuracy: 0.9091 - val_loss: 0.3616 - val_accuracy: 0.8000\n",
      "Epoch 145/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.2026 - accuracy: 0.9489 - val_loss: 0.3748 - val_accuracy: 0.8000\n",
      "Epoch 146/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2049 - accuracy: 0.9148 - val_loss: 0.3981 - val_accuracy: 0.8000\n",
      "Epoch 147/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.2163 - accuracy: 0.9205 - val_loss: 0.3552 - val_accuracy: 0.7500\n",
      "Epoch 148/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2001 - accuracy: 0.9375 - val_loss: 0.3990 - val_accuracy: 0.8000\n",
      "Epoch 149/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1985 - accuracy: 0.9205 - val_loss: 0.3598 - val_accuracy: 0.8000\n",
      "Epoch 150/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1979 - accuracy: 0.9489 - val_loss: 0.3710 - val_accuracy: 0.8000\n",
      "Epoch 151/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1978 - accuracy: 0.9205 - val_loss: 0.3799 - val_accuracy: 0.8000\n",
      "Epoch 152/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.2004 - accuracy: 0.9148 - val_loss: 0.3656 - val_accuracy: 0.8000\n",
      "Epoch 153/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.2069 - accuracy: 0.9318 - val_loss: 0.3492 - val_accuracy: 0.8000\n",
      "Epoch 154/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1922 - accuracy: 0.9489 - val_loss: 0.3972 - val_accuracy: 0.8000\n",
      "Epoch 155/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1978 - accuracy: 0.9091 - val_loss: 0.3688 - val_accuracy: 0.8000\n",
      "Epoch 156/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1924 - accuracy: 0.9489 - val_loss: 0.3505 - val_accuracy: 0.8000\n",
      "Epoch 157/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1968 - accuracy: 0.9432 - val_loss: 0.3648 - val_accuracy: 0.8000\n",
      "Epoch 158/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1931 - accuracy: 0.9432 - val_loss: 0.3543 - val_accuracy: 0.8000\n",
      "Epoch 159/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1925 - accuracy: 0.9489 - val_loss: 0.3545 - val_accuracy: 0.8000\n",
      "Epoch 160/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1910 - accuracy: 0.9318 - val_loss: 0.3896 - val_accuracy: 0.8000\n",
      "Epoch 161/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.1920 - accuracy: 0.9318 - val_loss: 0.3420 - val_accuracy: 0.8500\n",
      "Epoch 162/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1950 - accuracy: 0.9489 - val_loss: 0.3617 - val_accuracy: 0.8000\n",
      "Epoch 163/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1901 - accuracy: 0.9432 - val_loss: 0.3595 - val_accuracy: 0.8000\n",
      "Epoch 164/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1931 - accuracy: 0.9261 - val_loss: 0.3610 - val_accuracy: 0.8000\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1874 - accuracy: 0.9489 - val_loss: 0.3519 - val_accuracy: 0.8000\n",
      "Epoch 166/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1907 - accuracy: 0.9375 - val_loss: 0.3733 - val_accuracy: 0.8000\n",
      "Epoch 167/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1859 - accuracy: 0.9432 - val_loss: 0.3433 - val_accuracy: 0.8000\n",
      "Epoch 168/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1836 - accuracy: 0.9545 - val_loss: 0.3806 - val_accuracy: 0.8000\n",
      "Epoch 169/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1933 - accuracy: 0.9205 - val_loss: 0.3530 - val_accuracy: 0.8000\n",
      "Epoch 170/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1831 - accuracy: 0.9432 - val_loss: 0.3625 - val_accuracy: 0.8000\n",
      "Epoch 171/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1849 - accuracy: 0.9545 - val_loss: 0.3465 - val_accuracy: 0.8000\n",
      "Epoch 172/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1826 - accuracy: 0.9489 - val_loss: 0.3718 - val_accuracy: 0.8000\n",
      "Epoch 173/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1832 - accuracy: 0.9375 - val_loss: 0.3618 - val_accuracy: 0.8000\n",
      "Epoch 174/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1799 - accuracy: 0.9489 - val_loss: 0.3470 - val_accuracy: 0.8000\n",
      "Epoch 175/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1803 - accuracy: 0.9545 - val_loss: 0.3474 - val_accuracy: 0.8000\n",
      "Epoch 176/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1801 - accuracy: 0.9545 - val_loss: 0.3600 - val_accuracy: 0.8000\n",
      "Epoch 177/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1837 - accuracy: 0.9318 - val_loss: 0.3548 - val_accuracy: 0.8000\n",
      "Epoch 178/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.1781 - accuracy: 0.9489 - val_loss: 0.3436 - val_accuracy: 0.8000\n",
      "Epoch 179/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.1810 - accuracy: 0.9545 - val_loss: 0.3552 - val_accuracy: 0.8000\n",
      "Epoch 180/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1816 - accuracy: 0.9205 - val_loss: 0.3582 - val_accuracy: 0.8000\n",
      "Epoch 181/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1835 - accuracy: 0.9489 - val_loss: 0.3368 - val_accuracy: 0.8500\n",
      "Epoch 182/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1771 - accuracy: 0.9432 - val_loss: 0.3748 - val_accuracy: 0.8000\n",
      "Epoch 183/1000\n",
      "176/176 [==============================] - 0s 123us/sample - loss: 0.1787 - accuracy: 0.9432 - val_loss: 0.3384 - val_accuracy: 0.8000\n",
      "Epoch 184/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1772 - accuracy: 0.9489 - val_loss: 0.3492 - val_accuracy: 0.8000\n",
      "Epoch 185/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1756 - accuracy: 0.9545 - val_loss: 0.3382 - val_accuracy: 0.8000\n",
      "Epoch 186/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1759 - accuracy: 0.9489 - val_loss: 0.3546 - val_accuracy: 0.8000\n",
      "Epoch 187/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.1737 - accuracy: 0.9545 - val_loss: 0.3357 - val_accuracy: 0.8500\n",
      "Epoch 188/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1726 - accuracy: 0.9545 - val_loss: 0.3498 - val_accuracy: 0.8000\n",
      "Epoch 189/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1830 - accuracy: 0.9205 - val_loss: 0.3444 - val_accuracy: 0.8000\n",
      "Epoch 190/1000\n",
      "176/176 [==============================] - 0s 364us/sample - loss: 0.1899 - accuracy: 0.9318 - val_loss: 0.3278 - val_accuracy: 0.8500\n",
      "Epoch 191/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1716 - accuracy: 0.9375 - val_loss: 0.3793 - val_accuracy: 0.8000\n",
      "Epoch 192/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1748 - accuracy: 0.9318 - val_loss: 0.3332 - val_accuracy: 0.8500\n",
      "Epoch 193/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1741 - accuracy: 0.9545 - val_loss: 0.3359 - val_accuracy: 0.8500\n",
      "Epoch 194/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1751 - accuracy: 0.9432 - val_loss: 0.3457 - val_accuracy: 0.8000\n",
      "Epoch 195/1000\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.96 - 0s 136us/sample - loss: 0.1701 - accuracy: 0.9545 - val_loss: 0.3298 - val_accuracy: 0.8500\n",
      "Epoch 196/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1705 - accuracy: 0.9489 - val_loss: 0.3519 - val_accuracy: 0.8000\n",
      "Epoch 197/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1717 - accuracy: 0.9545 - val_loss: 0.3394 - val_accuracy: 0.8000\n",
      "Epoch 198/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1692 - accuracy: 0.9545 - val_loss: 0.3412 - val_accuracy: 0.8000\n",
      "Epoch 199/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.1688 - accuracy: 0.9545 - val_loss: 0.3271 - val_accuracy: 0.8500\n",
      "Epoch 200/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1689 - accuracy: 0.9489 - val_loss: 0.3401 - val_accuracy: 0.8000\n",
      "Epoch 201/1000\n",
      "176/176 [==============================] - 0s 364us/sample - loss: 0.1711 - accuracy: 0.9545 - val_loss: 0.3254 - val_accuracy: 0.8500\n",
      "Epoch 202/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1730 - accuracy: 0.9318 - val_loss: 0.3500 - val_accuracy: 0.8000\n",
      "Epoch 203/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.1646 - accuracy: 0.9545 - val_loss: 0.3213 - val_accuracy: 0.8500\n",
      "Epoch 204/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1666 - accuracy: 0.9545 - val_loss: 0.3437 - val_accuracy: 0.8000\n",
      "Epoch 205/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1696 - accuracy: 0.9489 - val_loss: 0.3285 - val_accuracy: 0.8500\n",
      "Epoch 206/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1626 - accuracy: 0.9545 - val_loss: 0.3473 - val_accuracy: 0.8000\n",
      "Epoch 207/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1672 - accuracy: 0.9432 - val_loss: 0.3332 - val_accuracy: 0.8000\n",
      "Epoch 208/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.1621 - accuracy: 0.9545 - val_loss: 0.3188 - val_accuracy: 0.8500\n",
      "Epoch 209/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1635 - accuracy: 0.9545 - val_loss: 0.3342 - val_accuracy: 0.8000\n",
      "Epoch 210/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1618 - accuracy: 0.9545 - val_loss: 0.3234 - val_accuracy: 0.8500\n",
      "Epoch 211/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.1833 - accuracy: 0.9375 - val_loss: 0.3209 - val_accuracy: 0.8500\n",
      "Epoch 212/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1662 - accuracy: 0.9375 - val_loss: 0.3672 - val_accuracy: 0.8000\n",
      "Epoch 213/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.1679 - accuracy: 0.9318 - val_loss: 0.3113 - val_accuracy: 0.8000\n",
      "Epoch 214/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1764 - accuracy: 0.9489 - val_loss: 0.3482 - val_accuracy: 0.8000\n",
      "Epoch 215/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1577 - accuracy: 0.9432 - val_loss: 0.3118 - val_accuracy: 0.8500\n",
      "Epoch 216/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1711 - accuracy: 0.9432 - val_loss: 0.3190 - val_accuracy: 0.8500\n",
      "Epoch 217/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1720 - accuracy: 0.9205 - val_loss: 0.3491 - val_accuracy: 0.8000\n",
      "Epoch 218/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1728 - accuracy: 0.9432 - val_loss: 0.3165 - val_accuracy: 0.8500\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1592 - accuracy: 0.9545 - val_loss: 0.3424 - val_accuracy: 0.8000\n",
      "Epoch 220/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1592 - accuracy: 0.9545 - val_loss: 0.3181 - val_accuracy: 0.8500\n",
      "Epoch 221/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1575 - accuracy: 0.9545 - val_loss: 0.3259 - val_accuracy: 0.8500\n",
      "Epoch 222/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.1583 - accuracy: 0.9545 - val_loss: 0.3185 - val_accuracy: 0.8500\n",
      "Epoch 223/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1591 - accuracy: 0.9545 - val_loss: 0.3251 - val_accuracy: 0.8500\n",
      "Epoch 224/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1556 - accuracy: 0.9545 - val_loss: 0.3182 - val_accuracy: 0.8500\n",
      "Epoch 225/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1556 - accuracy: 0.9489 - val_loss: 0.3135 - val_accuracy: 0.8500\n",
      "Epoch 226/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1561 - accuracy: 0.9545 - val_loss: 0.3352 - val_accuracy: 0.8000\n",
      "Epoch 227/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1598 - accuracy: 0.9489 - val_loss: 0.3134 - val_accuracy: 0.8500\n",
      "Epoch 228/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1578 - accuracy: 0.9432 - val_loss: 0.3114 - val_accuracy: 0.8500\n",
      "Epoch 229/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1524 - accuracy: 0.9545 - val_loss: 0.3268 - val_accuracy: 0.8500\n",
      "Epoch 230/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1532 - accuracy: 0.9545 - val_loss: 0.3303 - val_accuracy: 0.8000\n",
      "Epoch 231/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.1559 - accuracy: 0.9545 - val_loss: 0.3087 - val_accuracy: 0.8500\n",
      "Epoch 232/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1526 - accuracy: 0.9489 - val_loss: 0.3288 - val_accuracy: 0.8000\n",
      "Epoch 233/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.1602 - accuracy: 0.9602 - val_loss: 0.3066 - val_accuracy: 0.8500\n",
      "Epoch 234/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1613 - accuracy: 0.9318 - val_loss: 0.3341 - val_accuracy: 0.8000\n",
      "Epoch 235/1000\n",
      "176/176 [==============================] - 0s 364us/sample - loss: 0.1471 - accuracy: 0.9489 - val_loss: 0.3047 - val_accuracy: 0.8500\n",
      "Epoch 236/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1627 - accuracy: 0.9545 - val_loss: 0.3240 - val_accuracy: 0.8500\n",
      "Epoch 237/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1517 - accuracy: 0.9545 - val_loss: 0.3106 - val_accuracy: 0.8500\n",
      "Epoch 238/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1486 - accuracy: 0.9545 - val_loss: 0.3137 - val_accuracy: 0.8500\n",
      "Epoch 239/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1549 - accuracy: 0.9489 - val_loss: 0.3193 - val_accuracy: 0.8500\n",
      "Epoch 240/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1722 - accuracy: 0.9148 - val_loss: 0.3284 - val_accuracy: 0.8000\n",
      "Epoch 241/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.1530 - accuracy: 0.9545 - val_loss: 0.3031 - val_accuracy: 0.8500\n",
      "Epoch 242/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1576 - accuracy: 0.9489 - val_loss: 0.3368 - val_accuracy: 0.8000\n",
      "Epoch 243/1000\n",
      "176/176 [==============================] - 0s 205us/sample - loss: 0.1482 - accuracy: 0.9545 - val_loss: 0.3037 - val_accuracy: 0.8500\n",
      "Epoch 244/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1595 - accuracy: 0.9545 - val_loss: 0.3103 - val_accuracy: 0.8500\n",
      "Epoch 245/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1549 - accuracy: 0.9545 - val_loss: 0.3382 - val_accuracy: 0.8000\n",
      "Epoch 246/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.1430 - accuracy: 0.9545 - val_loss: 0.3008 - val_accuracy: 0.8500\n",
      "Epoch 247/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1494 - accuracy: 0.9545 - val_loss: 0.3141 - val_accuracy: 0.8500\n",
      "Epoch 248/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1495 - accuracy: 0.9545 - val_loss: 0.3106 - val_accuracy: 0.8500\n",
      "Epoch 249/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1521 - accuracy: 0.9545 - val_loss: 0.3061 - val_accuracy: 0.8500\n",
      "Epoch 250/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.1444 - accuracy: 0.9489 - val_loss: 0.3333 - val_accuracy: 0.8000\n",
      "Epoch 251/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.1452 - accuracy: 0.9602 - val_loss: 0.2976 - val_accuracy: 0.8500\n",
      "Epoch 252/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.1513 - accuracy: 0.9489 - val_loss: 0.2997 - val_accuracy: 0.8500\n",
      "Epoch 253/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1426 - accuracy: 0.9545 - val_loss: 0.3149 - val_accuracy: 0.8500\n",
      "Epoch 254/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1471 - accuracy: 0.9545 - val_loss: 0.3142 - val_accuracy: 0.8500\n",
      "Epoch 255/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.1442 - accuracy: 0.9545 - val_loss: 0.2965 - val_accuracy: 0.8500\n",
      "Epoch 256/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1421 - accuracy: 0.9545 - val_loss: 0.3077 - val_accuracy: 0.8500\n",
      "Epoch 257/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1567 - accuracy: 0.9375 - val_loss: 0.3028 - val_accuracy: 0.8500\n",
      "Epoch 258/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.1656 - accuracy: 0.9375 - val_loss: 0.2942 - val_accuracy: 0.8500\n",
      "Epoch 259/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1340 - accuracy: 0.9489 - val_loss: 0.3672 - val_accuracy: 0.8000\n",
      "Epoch 260/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.1603 - accuracy: 0.9261 - val_loss: 0.2915 - val_accuracy: 0.8500\n",
      "Epoch 261/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1457 - accuracy: 0.9489 - val_loss: 0.2948 - val_accuracy: 0.8500\n",
      "Epoch 262/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1470 - accuracy: 0.9545 - val_loss: 0.3037 - val_accuracy: 0.8500\n",
      "Epoch 263/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1436 - accuracy: 0.9545 - val_loss: 0.2998 - val_accuracy: 0.8500\n",
      "Epoch 264/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1382 - accuracy: 0.9545 - val_loss: 0.3031 - val_accuracy: 0.8500\n",
      "Epoch 265/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1385 - accuracy: 0.9545 - val_loss: 0.2968 - val_accuracy: 0.8500\n",
      "Epoch 266/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1380 - accuracy: 0.9545 - val_loss: 0.3000 - val_accuracy: 0.8500\n",
      "Epoch 267/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1545 - accuracy: 0.9375 - val_loss: 0.3036 - val_accuracy: 0.8500\n",
      "Epoch 268/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.1447 - accuracy: 0.9489 - val_loss: 0.2902 - val_accuracy: 0.8500\n",
      "Epoch 269/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1381 - accuracy: 0.9489 - val_loss: 0.3230 - val_accuracy: 0.8000\n",
      "Epoch 270/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.1478 - accuracy: 0.9375 - val_loss: 0.2894 - val_accuracy: 0.8500\n",
      "Epoch 271/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1383 - accuracy: 0.9545 - val_loss: 0.2912 - val_accuracy: 0.8500\n",
      "Epoch 272/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1399 - accuracy: 0.9545 - val_loss: 0.2909 - val_accuracy: 0.8500\n",
      "Epoch 273/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1352 - accuracy: 0.9545 - val_loss: 0.3018 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 274/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1396 - accuracy: 0.9545 - val_loss: 0.2895 - val_accuracy: 0.8500\n",
      "Epoch 275/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.1490 - accuracy: 0.9545 - val_loss: 0.2869 - val_accuracy: 0.8500\n",
      "Epoch 276/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1351 - accuracy: 0.9489 - val_loss: 0.3110 - val_accuracy: 0.8500\n",
      "Epoch 277/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1393 - accuracy: 0.9602 - val_loss: 0.2876 - val_accuracy: 0.8500\n",
      "Epoch 278/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.1472 - accuracy: 0.9489 - val_loss: 0.2895 - val_accuracy: 0.8500\n",
      "Epoch 279/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1411 - accuracy: 0.9489 - val_loss: 0.2965 - val_accuracy: 0.8500\n",
      "Epoch 280/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1351 - accuracy: 0.9489 - val_loss: 0.2878 - val_accuracy: 0.8500\n",
      "Epoch 281/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1319 - accuracy: 0.9545 - val_loss: 0.2946 - val_accuracy: 0.8500\n",
      "Epoch 282/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1366 - accuracy: 0.9489 - val_loss: 0.2923 - val_accuracy: 0.8500\n",
      "Epoch 283/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1331 - accuracy: 0.9545 - val_loss: 0.2856 - val_accuracy: 0.8500\n",
      "Epoch 284/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1322 - accuracy: 0.9545 - val_loss: 0.2935 - val_accuracy: 0.8500\n",
      "Epoch 285/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.1326 - accuracy: 0.9545 - val_loss: 0.2850 - val_accuracy: 0.8500\n",
      "Epoch 286/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1299 - accuracy: 0.9545 - val_loss: 0.2950 - val_accuracy: 0.8500\n",
      "Epoch 287/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1323 - accuracy: 0.9545 - val_loss: 0.2873 - val_accuracy: 0.8500\n",
      "Epoch 288/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1291 - accuracy: 0.9545 - val_loss: 0.2885 - val_accuracy: 0.8500\n",
      "Epoch 289/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1314 - accuracy: 0.9545 - val_loss: 0.2943 - val_accuracy: 0.8500\n",
      "Epoch 290/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.1269 - accuracy: 0.9545 - val_loss: 0.2844 - val_accuracy: 0.8500\n",
      "Epoch 291/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1411 - accuracy: 0.9489 - val_loss: 0.2852 - val_accuracy: 0.8500\n",
      "Epoch 292/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1255 - accuracy: 0.9545 - val_loss: 0.3059 - val_accuracy: 0.8500\n",
      "Epoch 293/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.1328 - accuracy: 0.9545 - val_loss: 0.2825 - val_accuracy: 0.8500\n",
      "Epoch 294/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1388 - accuracy: 0.9489 - val_loss: 0.2820 - val_accuracy: 0.8500\n",
      "Epoch 295/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1302 - accuracy: 0.9489 - val_loss: 0.2962 - val_accuracy: 0.8500\n",
      "Epoch 296/1000\n",
      "176/176 [==============================] - 0s 273us/sample - loss: 0.1346 - accuracy: 0.9545 - val_loss: 0.2779 - val_accuracy: 0.8500\n",
      "Epoch 297/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1328 - accuracy: 0.9545 - val_loss: 0.2855 - val_accuracy: 0.8500\n",
      "Epoch 298/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.1342 - accuracy: 0.9489 - val_loss: 0.2759 - val_accuracy: 0.8500\n",
      "Epoch 299/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1252 - accuracy: 0.9545 - val_loss: 0.2864 - val_accuracy: 0.8500\n",
      "Epoch 300/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1325 - accuracy: 0.9545 - val_loss: 0.2817 - val_accuracy: 0.8500\n",
      "Epoch 301/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1259 - accuracy: 0.9545 - val_loss: 0.2746 - val_accuracy: 0.8500\n",
      "Epoch 302/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1260 - accuracy: 0.9545 - val_loss: 0.2932 - val_accuracy: 0.8500\n",
      "Epoch 303/1000\n",
      "176/176 [==============================] - 0s 364us/sample - loss: 0.1263 - accuracy: 0.9545 - val_loss: 0.2736 - val_accuracy: 0.8500\n",
      "Epoch 304/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1258 - accuracy: 0.9602 - val_loss: 0.2749 - val_accuracy: 0.8500\n",
      "Epoch 305/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1250 - accuracy: 0.9545 - val_loss: 0.2777 - val_accuracy: 0.8500\n",
      "Epoch 306/1000\n",
      "176/176 [==============================] - 0s 123us/sample - loss: 0.1244 - accuracy: 0.9545 - val_loss: 0.2756 - val_accuracy: 0.8500\n",
      "Epoch 307/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1279 - accuracy: 0.9545 - val_loss: 0.2748 - val_accuracy: 0.8500\n",
      "Epoch 308/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1248 - accuracy: 0.9545 - val_loss: 0.2797 - val_accuracy: 0.8500\n",
      "Epoch 309/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1227 - accuracy: 0.9545 - val_loss: 0.2743 - val_accuracy: 0.8500\n",
      "Epoch 310/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1239 - accuracy: 0.9545 - val_loss: 0.2742 - val_accuracy: 0.8500\n",
      "Epoch 311/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1242 - accuracy: 0.9545 - val_loss: 0.2756 - val_accuracy: 0.8500\n",
      "Epoch 312/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1229 - accuracy: 0.9545 - val_loss: 0.2813 - val_accuracy: 0.8500\n",
      "Epoch 313/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1232 - accuracy: 0.9545 - val_loss: 0.2721 - val_accuracy: 0.8500\n",
      "Epoch 314/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.1234 - accuracy: 0.9545 - val_loss: 0.2717 - val_accuracy: 0.8500\n",
      "Epoch 315/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1217 - accuracy: 0.9545 - val_loss: 0.2827 - val_accuracy: 0.8500\n",
      "Epoch 316/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.1201 - accuracy: 0.9545 - val_loss: 0.2690 - val_accuracy: 0.8500\n",
      "Epoch 317/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1317 - accuracy: 0.9489 - val_loss: 0.2702 - val_accuracy: 0.8500\n",
      "Epoch 318/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.1198 - accuracy: 0.9545 - val_loss: 0.2683 - val_accuracy: 0.8500\n",
      "Epoch 319/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1208 - accuracy: 0.9602 - val_loss: 0.2708 - val_accuracy: 0.8500\n",
      "Epoch 320/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1196 - accuracy: 0.9545 - val_loss: 0.2735 - val_accuracy: 0.8500\n",
      "Epoch 321/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1247 - accuracy: 0.9432 - val_loss: 0.2732 - val_accuracy: 0.8500\n",
      "Epoch 322/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.1259 - accuracy: 0.9602 - val_loss: 0.2683 - val_accuracy: 0.8500\n",
      "Epoch 323/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1313 - accuracy: 0.9545 - val_loss: 0.2895 - val_accuracy: 0.8500\n",
      "Epoch 324/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1208 - accuracy: 0.9545 - val_loss: 0.2696 - val_accuracy: 0.8500\n",
      "Epoch 325/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1227 - accuracy: 0.9545 - val_loss: 0.2786 - val_accuracy: 0.8500\n",
      "Epoch 326/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1204 - accuracy: 0.9659 - val_loss: 0.2683 - val_accuracy: 0.8500\n",
      "Epoch 327/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1163 - accuracy: 0.9545 - val_loss: 0.2754 - val_accuracy: 0.8500\n",
      "Epoch 328/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1192 - accuracy: 0.9545 - val_loss: 0.2696 - val_accuracy: 0.8500\n",
      "Epoch 329/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1203 - accuracy: 0.9602 - val_loss: 0.2675 - val_accuracy: 0.8500\n",
      "Epoch 330/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1183 - accuracy: 0.9602 - val_loss: 0.2763 - val_accuracy: 0.8500\n",
      "Epoch 331/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1148 - accuracy: 0.9545 - val_loss: 0.2658 - val_accuracy: 0.8500\n",
      "Epoch 332/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1166 - accuracy: 0.9545 - val_loss: 0.2663 - val_accuracy: 0.8500\n",
      "Epoch 333/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1151 - accuracy: 0.9545 - val_loss: 0.2640 - val_accuracy: 0.8500\n",
      "Epoch 334/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1153 - accuracy: 0.9602 - val_loss: 0.2622 - val_accuracy: 0.8500\n",
      "Epoch 335/1000\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 1.00 - 0s 114us/sample - loss: 0.1163 - accuracy: 0.9602 - val_loss: 0.2682 - val_accuracy: 0.8500\n",
      "Epoch 336/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1155 - accuracy: 0.9545 - val_loss: 0.2625 - val_accuracy: 0.8500\n",
      "Epoch 337/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1224 - accuracy: 0.9545 - val_loss: 0.2635 - val_accuracy: 0.8500\n",
      "Epoch 338/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1131 - accuracy: 0.9545 - val_loss: 0.2680 - val_accuracy: 0.8500\n",
      "Epoch 339/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.1123 - accuracy: 0.9545 - val_loss: 0.2636 - val_accuracy: 0.8500\n",
      "Epoch 340/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1177 - accuracy: 0.9545 - val_loss: 0.2630 - val_accuracy: 0.8500\n",
      "Epoch 341/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1263 - accuracy: 0.9545 - val_loss: 0.2619 - val_accuracy: 0.8500\n",
      "Epoch 342/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1103 - accuracy: 0.9545 - val_loss: 0.2767 - val_accuracy: 0.8500\n",
      "Epoch 343/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.1153 - accuracy: 0.9602 - val_loss: 0.2610 - val_accuracy: 0.8500\n",
      "Epoch 344/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1172 - accuracy: 0.9602 - val_loss: 0.2663 - val_accuracy: 0.8500\n",
      "Epoch 345/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.1339 - accuracy: 0.9545 - val_loss: 0.2706 - val_accuracy: 0.8500\n",
      "Epoch 346/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1206 - accuracy: 0.9545 - val_loss: 0.2615 - val_accuracy: 0.8500\n",
      "Epoch 347/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1204 - accuracy: 0.9602 - val_loss: 0.2683 - val_accuracy: 0.8500\n",
      "Epoch 348/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.1132 - accuracy: 0.9545 - val_loss: 0.2606 - val_accuracy: 0.8500\n",
      "Epoch 349/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1111 - accuracy: 0.9602 - val_loss: 0.2672 - val_accuracy: 0.8500\n",
      "Epoch 350/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1125 - accuracy: 0.9545 - val_loss: 0.2708 - val_accuracy: 0.8500\n",
      "Epoch 351/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1114 - accuracy: 0.9659 - val_loss: 0.2607 - val_accuracy: 0.8500\n",
      "Epoch 352/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.1112 - accuracy: 0.9545 - val_loss: 0.2602 - val_accuracy: 0.8500\n",
      "Epoch 353/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.1140 - accuracy: 0.9602 - val_loss: 0.2641 - val_accuracy: 0.8500\n",
      "Epoch 354/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1118 - accuracy: 0.9602 - val_loss: 0.2581 - val_accuracy: 0.8500\n",
      "Epoch 355/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.1167 - accuracy: 0.9659 - val_loss: 0.2576 - val_accuracy: 0.8500\n",
      "Epoch 356/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1186 - accuracy: 0.9659 - val_loss: 0.2721 - val_accuracy: 0.8500\n",
      "Epoch 357/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1022 - accuracy: 0.9545 - val_loss: 0.2661 - val_accuracy: 0.8500\n",
      "Epoch 358/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1230 - accuracy: 0.9545 - val_loss: 0.2630 - val_accuracy: 0.8500\n",
      "Epoch 359/1000\n",
      "176/176 [==============================] - 0s 273us/sample - loss: 0.1140 - accuracy: 0.9489 - val_loss: 0.2538 - val_accuracy: 0.8500\n",
      "Epoch 360/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1077 - accuracy: 0.9602 - val_loss: 0.2538 - val_accuracy: 0.8500\n",
      "Epoch 361/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1057 - accuracy: 0.9545 - val_loss: 0.2570 - val_accuracy: 0.8500\n",
      "Epoch 362/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1076 - accuracy: 0.9602 - val_loss: 0.2541 - val_accuracy: 0.8500\n",
      "Epoch 363/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1053 - accuracy: 0.9602 - val_loss: 0.2561 - val_accuracy: 0.8500\n",
      "Epoch 364/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1074 - accuracy: 0.9545 - val_loss: 0.2562 - val_accuracy: 0.8500\n",
      "Epoch 365/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1081 - accuracy: 0.9659 - val_loss: 0.2553 - val_accuracy: 0.8500\n",
      "Epoch 366/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1111 - accuracy: 0.9489 - val_loss: 0.2582 - val_accuracy: 0.8500\n",
      "Epoch 367/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1098 - accuracy: 0.9545 - val_loss: 0.2541 - val_accuracy: 0.8500\n",
      "Epoch 368/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1131 - accuracy: 0.9602 - val_loss: 0.2586 - val_accuracy: 0.8500\n",
      "Epoch 369/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1087 - accuracy: 0.9545 - val_loss: 0.2551 - val_accuracy: 0.8500\n",
      "Epoch 370/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1028 - accuracy: 0.9602 - val_loss: 0.2613 - val_accuracy: 0.8500\n",
      "Epoch 371/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.1061 - accuracy: 0.9602 - val_loss: 0.2534 - val_accuracy: 0.8500\n",
      "Epoch 372/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.1048 - accuracy: 0.9545 - val_loss: 0.2532 - val_accuracy: 0.8500\n",
      "Epoch 373/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1047 - accuracy: 0.9545 - val_loss: 0.2536 - val_accuracy: 0.8500\n",
      "Epoch 374/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.1026 - accuracy: 0.9545 - val_loss: 0.2515 - val_accuracy: 0.8500\n",
      "Epoch 375/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1051 - accuracy: 0.9602 - val_loss: 0.2516 - val_accuracy: 0.8500\n",
      "Epoch 376/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1086 - accuracy: 0.9659 - val_loss: 0.2522 - val_accuracy: 0.8500\n",
      "Epoch 377/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1150 - accuracy: 0.9602 - val_loss: 0.2521 - val_accuracy: 0.8500\n",
      "Epoch 378/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.1016 - accuracy: 0.9602 - val_loss: 0.2578 - val_accuracy: 0.8500\n",
      "Epoch 379/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.1044 - accuracy: 0.9602 - val_loss: 0.2512 - val_accuracy: 0.8500\n",
      "Epoch 380/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1004 - accuracy: 0.9602 - val_loss: 0.2524 - val_accuracy: 0.8500\n",
      "Epoch 381/1000\n",
      "176/176 [==============================] - 0s 364us/sample - loss: 0.1000 - accuracy: 0.9602 - val_loss: 0.2500 - val_accuracy: 0.8500\n",
      "Epoch 382/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1072 - accuracy: 0.9602 - val_loss: 0.2516 - val_accuracy: 0.8500\n",
      "Epoch 383/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.0996 - accuracy: 0.9659 - val_loss: 0.2476 - val_accuracy: 0.8500\n",
      "Epoch 384/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1067 - accuracy: 0.9545 - val_loss: 0.2520 - val_accuracy: 0.8500\n",
      "Epoch 385/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.1030 - accuracy: 0.9659 - val_loss: 0.2458 - val_accuracy: 0.8500\n",
      "Epoch 386/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0978 - accuracy: 0.9602 - val_loss: 0.2511 - val_accuracy: 0.8500\n",
      "Epoch 387/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.1056 - accuracy: 0.9602 - val_loss: 0.2449 - val_accuracy: 0.8500\n",
      "Epoch 388/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1008 - accuracy: 0.9659 - val_loss: 0.2455 - val_accuracy: 0.8500\n",
      "Epoch 389/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1015 - accuracy: 0.9602 - val_loss: 0.2471 - val_accuracy: 0.8500\n",
      "Epoch 390/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1101 - accuracy: 0.9602 - val_loss: 0.2451 - val_accuracy: 0.8500\n",
      "Epoch 391/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.1018 - accuracy: 0.9659 - val_loss: 0.2469 - val_accuracy: 0.8500\n",
      "Epoch 392/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.0965 - accuracy: 0.9659 - val_loss: 0.2438 - val_accuracy: 0.8500\n",
      "Epoch 393/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0985 - accuracy: 0.9659 - val_loss: 0.2452 - val_accuracy: 0.8500\n",
      "Epoch 394/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1033 - accuracy: 0.9602 - val_loss: 0.2444 - val_accuracy: 0.8500\n",
      "Epoch 395/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1025 - accuracy: 0.9602 - val_loss: 0.2440 - val_accuracy: 0.8500\n",
      "Epoch 396/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1054 - accuracy: 0.9659 - val_loss: 0.2538 - val_accuracy: 0.8500\n",
      "Epoch 397/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0991 - accuracy: 0.9659 - val_loss: 0.2451 - val_accuracy: 0.8500\n",
      "Epoch 398/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0966 - accuracy: 0.9659 - val_loss: 0.2450 - val_accuracy: 0.8500\n",
      "Epoch 399/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0980 - accuracy: 0.9602 - val_loss: 0.2442 - val_accuracy: 0.8500\n",
      "Epoch 400/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0973 - accuracy: 0.9659 - val_loss: 0.2426 - val_accuracy: 0.8500\n",
      "Epoch 401/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0948 - accuracy: 0.9659 - val_loss: 0.2446 - val_accuracy: 0.8500\n",
      "Epoch 402/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.0942 - accuracy: 0.9659 - val_loss: 0.2417 - val_accuracy: 0.8500\n",
      "Epoch 403/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.0990 - accuracy: 0.9659 - val_loss: 0.2414 - val_accuracy: 0.8500\n",
      "Epoch 404/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.1022 - accuracy: 0.9716 - val_loss: 0.2483 - val_accuracy: 0.8500\n",
      "Epoch 405/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0948 - accuracy: 0.9716 - val_loss: 0.2424 - val_accuracy: 0.8500\n",
      "Epoch 406/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0972 - accuracy: 0.9659 - val_loss: 0.2418 - val_accuracy: 0.8500\n",
      "Epoch 407/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0987 - accuracy: 0.9659 - val_loss: 0.2425 - val_accuracy: 0.8500\n",
      "Epoch 408/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1003 - accuracy: 0.9545 - val_loss: 0.2458 - val_accuracy: 0.8500\n",
      "Epoch 409/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0923 - accuracy: 0.9659 - val_loss: 0.2430 - val_accuracy: 0.8500\n",
      "Epoch 410/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0912 - accuracy: 0.9659 - val_loss: 0.2458 - val_accuracy: 0.8500\n",
      "Epoch 411/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.0968 - accuracy: 0.9659 - val_loss: 0.2402 - val_accuracy: 0.8500\n",
      "Epoch 412/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0952 - accuracy: 0.9716 - val_loss: 0.2404 - val_accuracy: 0.8500\n",
      "Epoch 413/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0943 - accuracy: 0.9659 - val_loss: 0.2417 - val_accuracy: 0.8500\n",
      "Epoch 414/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0940 - accuracy: 0.9659 - val_loss: 0.2404 - val_accuracy: 0.8500\n",
      "Epoch 415/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0925 - accuracy: 0.9602 - val_loss: 0.2412 - val_accuracy: 0.8500\n",
      "Epoch 416/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0930 - accuracy: 0.9659 - val_loss: 0.2428 - val_accuracy: 0.8500\n",
      "Epoch 417/1000\n",
      "176/176 [==============================] - 0s 500us/sample - loss: 0.0914 - accuracy: 0.9716 - val_loss: 0.2397 - val_accuracy: 0.8500\n",
      "Epoch 418/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0912 - accuracy: 0.9659 - val_loss: 0.2400 - val_accuracy: 0.8500\n",
      "Epoch 419/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.0960 - accuracy: 0.9716 - val_loss: 0.2393 - val_accuracy: 0.8500\n",
      "Epoch 420/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0915 - accuracy: 0.9659 - val_loss: 0.2389 - val_accuracy: 0.8500\n",
      "Epoch 421/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0910 - accuracy: 0.9659 - val_loss: 0.2415 - val_accuracy: 0.8500\n",
      "Epoch 422/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0898 - accuracy: 0.9773 - val_loss: 0.2390 - val_accuracy: 0.8500\n",
      "Epoch 423/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0900 - accuracy: 0.9659 - val_loss: 0.2394 - val_accuracy: 0.8500\n",
      "Epoch 424/1000\n",
      "176/176 [==============================] - 0s 477us/sample - loss: 0.0885 - accuracy: 0.9659 - val_loss: 0.2374 - val_accuracy: 0.8500\n",
      "Epoch 425/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0888 - accuracy: 0.9659 - val_loss: 0.2380 - val_accuracy: 0.8500\n",
      "Epoch 426/1000\n",
      "176/176 [==============================] - 0s 523us/sample - loss: 0.0883 - accuracy: 0.9716 - val_loss: 0.2372 - val_accuracy: 0.8500\n",
      "Epoch 427/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0918 - accuracy: 0.9773 - val_loss: 0.2358 - val_accuracy: 0.8500\n",
      "Epoch 428/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0991 - accuracy: 0.9602 - val_loss: 0.2359 - val_accuracy: 0.8500\n",
      "Epoch 429/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0889 - accuracy: 0.9659 - val_loss: 0.2369 - val_accuracy: 0.8500\n",
      "Epoch 430/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0956 - accuracy: 0.9659 - val_loss: 0.2378 - val_accuracy: 0.8500\n",
      "Epoch 431/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.0892 - accuracy: 0.9716 - val_loss: 0.2380 - val_accuracy: 0.8500\n",
      "Epoch 432/1000\n",
      "176/176 [==============================] - 0s 145us/sample - loss: 0.0868 - accuracy: 0.9659 - val_loss: 0.2451 - val_accuracy: 0.8500\n",
      "Epoch 433/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0902 - accuracy: 0.9716 - val_loss: 0.2364 - val_accuracy: 0.8500\n",
      "Epoch 434/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0853 - accuracy: 0.9659 - val_loss: 0.2403 - val_accuracy: 0.8500\n",
      "Epoch 435/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0891 - accuracy: 0.9716 - val_loss: 0.2374 - val_accuracy: 0.8500\n",
      "Epoch 436/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0883 - accuracy: 0.9773 - val_loss: 0.2360 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0957 - accuracy: 0.9659 - val_loss: 0.2340 - val_accuracy: 0.8500\n",
      "Epoch 438/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0870 - accuracy: 0.9716 - val_loss: 0.2374 - val_accuracy: 0.8500\n",
      "Epoch 439/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0887 - accuracy: 0.9716 - val_loss: 0.2347 - val_accuracy: 0.8500\n",
      "Epoch 440/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.0922 - accuracy: 0.9773 - val_loss: 0.2320 - val_accuracy: 0.8500\n",
      "Epoch 441/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0914 - accuracy: 0.9659 - val_loss: 0.2323 - val_accuracy: 0.8500\n",
      "Epoch 442/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0873 - accuracy: 0.9773 - val_loss: 0.2349 - val_accuracy: 0.8500\n",
      "Epoch 443/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0848 - accuracy: 0.9830 - val_loss: 0.2328 - val_accuracy: 0.8500\n",
      "Epoch 444/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0922 - accuracy: 0.9602 - val_loss: 0.2351 - val_accuracy: 0.8500\n",
      "Epoch 445/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0886 - accuracy: 0.9716 - val_loss: 0.2325 - val_accuracy: 0.8500\n",
      "Epoch 446/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0836 - accuracy: 0.9716 - val_loss: 0.2328 - val_accuracy: 0.8500\n",
      "Epoch 447/1000\n",
      "176/176 [==============================] - 0s 500us/sample - loss: 0.0867 - accuracy: 0.9716 - val_loss: 0.2314 - val_accuracy: 0.8500\n",
      "Epoch 448/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0869 - accuracy: 0.9659 - val_loss: 0.2315 - val_accuracy: 0.8500\n",
      "Epoch 449/1000\n",
      "176/176 [==============================] - 0s 500us/sample - loss: 0.0829 - accuracy: 0.9659 - val_loss: 0.2301 - val_accuracy: 0.8500\n",
      "Epoch 450/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.0837 - accuracy: 0.9773 - val_loss: 0.2294 - val_accuracy: 0.8500\n",
      "Epoch 451/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.0858 - accuracy: 0.9773 - val_loss: 0.2286 - val_accuracy: 0.8500\n",
      "Epoch 452/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1087 - accuracy: 0.9602 - val_loss: 0.2295 - val_accuracy: 0.8500\n",
      "Epoch 453/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.1019 - accuracy: 0.9545 - val_loss: 0.2354 - val_accuracy: 0.8500\n",
      "Epoch 454/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0791 - accuracy: 0.9830 - val_loss: 0.2446 - val_accuracy: 0.8500\n",
      "Epoch 455/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0939 - accuracy: 0.9716 - val_loss: 0.2402 - val_accuracy: 0.8500\n",
      "Epoch 456/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0861 - accuracy: 0.9659 - val_loss: 0.2350 - val_accuracy: 0.8500\n",
      "Epoch 457/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0906 - accuracy: 0.9659 - val_loss: 0.2388 - val_accuracy: 0.8500\n",
      "Epoch 458/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0905 - accuracy: 0.9773 - val_loss: 0.2323 - val_accuracy: 0.8500\n",
      "Epoch 459/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0763 - accuracy: 0.9830 - val_loss: 0.2432 - val_accuracy: 0.8500\n",
      "Epoch 460/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.1009 - accuracy: 0.9602 - val_loss: 0.2336 - val_accuracy: 0.8500\n",
      "Epoch 461/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0836 - accuracy: 0.9773 - val_loss: 0.2301 - val_accuracy: 0.8500\n",
      "Epoch 462/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0870 - accuracy: 0.9659 - val_loss: 0.2286 - val_accuracy: 0.8500\n",
      "Epoch 463/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0847 - accuracy: 0.9773 - val_loss: 0.2302 - val_accuracy: 0.8500\n",
      "Epoch 464/1000\n",
      "176/176 [==============================] - 0s 477us/sample - loss: 0.0858 - accuracy: 0.9659 - val_loss: 0.2285 - val_accuracy: 0.8500\n",
      "Epoch 465/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0802 - accuracy: 0.9773 - val_loss: 0.2287 - val_accuracy: 0.8500\n",
      "Epoch 466/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0789 - accuracy: 0.9773 - val_loss: 0.2297 - val_accuracy: 0.8500\n",
      "Epoch 467/1000\n",
      "176/176 [==============================] - 0s 477us/sample - loss: 0.0828 - accuracy: 0.9773 - val_loss: 0.2264 - val_accuracy: 0.8500\n",
      "Epoch 468/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.0939 - accuracy: 0.9659 - val_loss: 0.2246 - val_accuracy: 0.8500\n",
      "Epoch 469/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0865 - accuracy: 0.9716 - val_loss: 0.2350 - val_accuracy: 0.8500\n",
      "Epoch 470/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0764 - accuracy: 0.9716 - val_loss: 0.2383 - val_accuracy: 0.8500\n",
      "Epoch 471/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0878 - accuracy: 0.9545 - val_loss: 0.2329 - val_accuracy: 0.8500\n",
      "Epoch 472/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0880 - accuracy: 0.9602 - val_loss: 0.2247 - val_accuracy: 0.8500\n",
      "Epoch 473/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0789 - accuracy: 0.9773 - val_loss: 0.2252 - val_accuracy: 0.8500\n",
      "Epoch 474/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0783 - accuracy: 0.9830 - val_loss: 0.2256 - val_accuracy: 0.8500\n",
      "Epoch 475/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0780 - accuracy: 0.9830 - val_loss: 0.2272 - val_accuracy: 0.8500\n",
      "Epoch 476/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0773 - accuracy: 0.9716 - val_loss: 0.2291 - val_accuracy: 0.8500\n",
      "Epoch 477/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0825 - accuracy: 0.9716 - val_loss: 0.2256 - val_accuracy: 0.8500\n",
      "Epoch 478/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0841 - accuracy: 0.9716 - val_loss: 0.2257 - val_accuracy: 0.8500\n",
      "Epoch 479/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0841 - accuracy: 0.9716 - val_loss: 0.2270 - val_accuracy: 0.8500\n",
      "Epoch 480/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0854 - accuracy: 0.9773 - val_loss: 0.2269 - val_accuracy: 0.8500\n",
      "Epoch 481/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0904 - accuracy: 0.9659 - val_loss: 0.2280 - val_accuracy: 0.8500\n",
      "Epoch 482/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0892 - accuracy: 0.9716 - val_loss: 0.2333 - val_accuracy: 0.8500\n",
      "Epoch 483/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0768 - accuracy: 0.9716 - val_loss: 0.2383 - val_accuracy: 0.8500\n",
      "Epoch 484/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0780 - accuracy: 0.9773 - val_loss: 0.2351 - val_accuracy: 0.8500\n",
      "Epoch 485/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0898 - accuracy: 0.9659 - val_loss: 0.2253 - val_accuracy: 0.8500\n",
      "Epoch 486/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.0763 - accuracy: 0.9716 - val_loss: 0.2235 - val_accuracy: 0.8500\n",
      "Epoch 487/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0741 - accuracy: 0.9830 - val_loss: 0.2250 - val_accuracy: 0.8500\n",
      "Epoch 488/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0767 - accuracy: 0.9773 - val_loss: 0.2224 - val_accuracy: 0.8500\n",
      "Epoch 489/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0781 - accuracy: 0.9773 - val_loss: 0.2247 - val_accuracy: 0.8500\n",
      "Epoch 490/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0862 - accuracy: 0.9659 - val_loss: 0.2249 - val_accuracy: 0.8500\n",
      "Epoch 491/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0864 - accuracy: 0.9716 - val_loss: 0.2242 - val_accuracy: 0.8500\n",
      "Epoch 492/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0729 - accuracy: 0.9830 - val_loss: 0.2319 - val_accuracy: 0.8500\n",
      "Epoch 493/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0787 - accuracy: 0.9830 - val_loss: 0.2234 - val_accuracy: 0.8500\n",
      "Epoch 494/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.0758 - accuracy: 0.9716 - val_loss: 0.2223 - val_accuracy: 0.8500\n",
      "Epoch 495/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.0731 - accuracy: 0.9830 - val_loss: 0.2222 - val_accuracy: 0.8500\n",
      "Epoch 496/1000\n",
      "176/176 [==============================] - 0s 364us/sample - loss: 0.0752 - accuracy: 0.9830 - val_loss: 0.2220 - val_accuracy: 0.8500\n",
      "Epoch 497/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0737 - accuracy: 0.9773 - val_loss: 0.2224 - val_accuracy: 0.8500\n",
      "Epoch 498/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.0817 - accuracy: 0.9716 - val_loss: 0.2200 - val_accuracy: 0.8500\n",
      "Epoch 499/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.1033 - accuracy: 0.9659 - val_loss: 0.2210 - val_accuracy: 0.8500\n",
      "Epoch 500/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.0811 - accuracy: 0.9716 - val_loss: 0.2203 - val_accuracy: 0.8500\n",
      "Epoch 501/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0732 - accuracy: 0.9830 - val_loss: 0.2223 - val_accuracy: 0.8500\n",
      "Epoch 502/1000\n",
      "176/176 [==============================] - 0s 273us/sample - loss: 0.0831 - accuracy: 0.9659 - val_loss: 0.2199 - val_accuracy: 0.8500\n",
      "Epoch 503/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0725 - accuracy: 0.9773 - val_loss: 0.2236 - val_accuracy: 0.8500\n",
      "Epoch 504/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0767 - accuracy: 0.9716 - val_loss: 0.2206 - val_accuracy: 0.8500\n",
      "Epoch 505/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0738 - accuracy: 0.9830 - val_loss: 0.2212 - val_accuracy: 0.8500\n",
      "Epoch 506/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0738 - accuracy: 0.9830 - val_loss: 0.2219 - val_accuracy: 0.8500\n",
      "Epoch 507/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0719 - accuracy: 0.9773 - val_loss: 0.2233 - val_accuracy: 0.8500\n",
      "Epoch 508/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0709 - accuracy: 0.9830 - val_loss: 0.2235 - val_accuracy: 0.8500\n",
      "Epoch 509/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0752 - accuracy: 0.9773 - val_loss: 0.2238 - val_accuracy: 0.8500\n",
      "Epoch 510/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0720 - accuracy: 0.9886 - val_loss: 0.2209 - val_accuracy: 0.8500\n",
      "Epoch 511/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0722 - accuracy: 0.9830 - val_loss: 0.2205 - val_accuracy: 0.8500\n",
      "Epoch 512/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.0702 - accuracy: 0.9830 - val_loss: 0.2229 - val_accuracy: 0.8500\n",
      "Epoch 513/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0723 - accuracy: 0.9830 - val_loss: 0.2240 - val_accuracy: 0.8500\n",
      "Epoch 514/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0685 - accuracy: 0.9830 - val_loss: 0.2239 - val_accuracy: 0.8500\n",
      "Epoch 515/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0716 - accuracy: 0.9886 - val_loss: 0.2228 - val_accuracy: 0.8500\n",
      "Epoch 516/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0796 - accuracy: 0.9716 - val_loss: 0.2207 - val_accuracy: 0.8500\n",
      "Epoch 517/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0673 - accuracy: 0.9830 - val_loss: 0.2244 - val_accuracy: 0.8500\n",
      "Epoch 518/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.0770 - accuracy: 0.9773 - val_loss: 0.2179 - val_accuracy: 0.8500\n",
      "Epoch 519/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0678 - accuracy: 0.9886 - val_loss: 0.2180 - val_accuracy: 0.8500\n",
      "Epoch 520/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0695 - accuracy: 0.9886 - val_loss: 0.2193 - val_accuracy: 0.8500\n",
      "Epoch 521/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0684 - accuracy: 0.9886 - val_loss: 0.2179 - val_accuracy: 0.8500\n",
      "Epoch 522/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0710 - accuracy: 0.9830 - val_loss: 0.2185 - val_accuracy: 0.8500\n",
      "Epoch 523/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.0687 - accuracy: 0.9830 - val_loss: 0.2175 - val_accuracy: 0.8500\n",
      "Epoch 524/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0689 - accuracy: 0.9830 - val_loss: 0.2197 - val_accuracy: 0.8500\n",
      "Epoch 525/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.0759 - accuracy: 0.9716 - val_loss: 0.2171 - val_accuracy: 0.8500\n",
      "Epoch 526/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0667 - accuracy: 0.9830 - val_loss: 0.2178 - val_accuracy: 0.8500\n",
      "Epoch 527/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.0685 - accuracy: 0.9886 - val_loss: 0.2156 - val_accuracy: 0.8500\n",
      "Epoch 528/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.0681 - accuracy: 0.9886 - val_loss: 0.2154 - val_accuracy: 0.8500\n",
      "Epoch 529/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0670 - accuracy: 0.9886 - val_loss: 0.2163 - val_accuracy: 0.8500\n",
      "Epoch 530/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.0689 - accuracy: 0.9773 - val_loss: 0.2147 - val_accuracy: 0.8500\n",
      "Epoch 531/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0677 - accuracy: 0.9886 - val_loss: 0.2161 - val_accuracy: 0.8500\n",
      "Epoch 532/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0661 - accuracy: 0.9886 - val_loss: 0.2164 - val_accuracy: 0.8500\n",
      "Epoch 533/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0682 - accuracy: 0.9886 - val_loss: 0.2149 - val_accuracy: 0.8500\n",
      "Epoch 534/1000\n",
      "176/176 [==============================] - 0s 273us/sample - loss: 0.0673 - accuracy: 0.9830 - val_loss: 0.2131 - val_accuracy: 0.8500\n",
      "Epoch 535/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.0678 - accuracy: 0.9886 - val_loss: 0.2121 - val_accuracy: 0.8500\n",
      "Epoch 536/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0669 - accuracy: 0.9830 - val_loss: 0.2131 - val_accuracy: 0.8500\n",
      "Epoch 537/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0691 - accuracy: 0.9886 - val_loss: 0.2138 - val_accuracy: 0.8500\n",
      "Epoch 538/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0763 - accuracy: 0.9773 - val_loss: 0.2147 - val_accuracy: 0.8500\n",
      "Epoch 539/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0769 - accuracy: 0.9716 - val_loss: 0.2196 - val_accuracy: 0.8500\n",
      "Epoch 540/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0707 - accuracy: 0.9773 - val_loss: 0.2204 - val_accuracy: 0.8500\n",
      "Epoch 541/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0733 - accuracy: 0.9773 - val_loss: 0.2151 - val_accuracy: 0.8500\n",
      "Epoch 542/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0679 - accuracy: 0.9886 - val_loss: 0.2149 - val_accuracy: 0.8500\n",
      "Epoch 543/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0706 - accuracy: 0.9830 - val_loss: 0.2143 - val_accuracy: 0.8500\n",
      "Epoch 544/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0639 - accuracy: 0.9830 - val_loss: 0.2158 - val_accuracy: 0.8500\n",
      "Epoch 545/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0632 - accuracy: 0.9886 - val_loss: 0.2147 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.0686 - accuracy: 0.9886 - val_loss: 0.2117 - val_accuracy: 0.8500\n",
      "Epoch 547/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.0672 - accuracy: 0.9830 - val_loss: 0.2116 - val_accuracy: 0.8500\n",
      "Epoch 548/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0702 - accuracy: 0.9773 - val_loss: 0.2139 - val_accuracy: 0.8500\n",
      "Epoch 549/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0713 - accuracy: 0.9716 - val_loss: 0.2161 - val_accuracy: 0.8500\n",
      "Epoch 550/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0717 - accuracy: 0.9830 - val_loss: 0.2146 - val_accuracy: 0.8500\n",
      "Epoch 551/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0678 - accuracy: 0.9830 - val_loss: 0.2124 - val_accuracy: 0.8500\n",
      "Epoch 552/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0657 - accuracy: 0.9830 - val_loss: 0.2110 - val_accuracy: 0.8500\n",
      "Epoch 553/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0622 - accuracy: 0.9886 - val_loss: 0.2130 - val_accuracy: 0.8500\n",
      "Epoch 554/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0636 - accuracy: 0.9886 - val_loss: 0.2127 - val_accuracy: 0.8500\n",
      "Epoch 555/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0668 - accuracy: 0.9886 - val_loss: 0.2125 - val_accuracy: 0.8500\n",
      "Epoch 556/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0696 - accuracy: 0.9773 - val_loss: 0.2118 - val_accuracy: 0.8500\n",
      "Epoch 557/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0649 - accuracy: 0.9886 - val_loss: 0.2107 - val_accuracy: 0.8500\n",
      "Epoch 558/1000\n",
      "176/176 [==============================] - 0s 132us/sample - loss: 0.0624 - accuracy: 0.9886 - val_loss: 0.2122 - val_accuracy: 0.8500\n",
      "Epoch 559/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0664 - accuracy: 0.9886 - val_loss: 0.2115 - val_accuracy: 0.8500\n",
      "Epoch 560/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.0655 - accuracy: 0.9830 - val_loss: 0.2102 - val_accuracy: 0.8500\n",
      "Epoch 561/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0654 - accuracy: 0.9830 - val_loss: 0.2108 - val_accuracy: 0.8500\n",
      "Epoch 562/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0621 - accuracy: 0.9886 - val_loss: 0.2115 - val_accuracy: 0.8500\n",
      "Epoch 563/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0607 - accuracy: 0.9886 - val_loss: 0.2118 - val_accuracy: 0.8500\n",
      "Epoch 564/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0646 - accuracy: 0.9886 - val_loss: 0.2120 - val_accuracy: 0.8500\n",
      "Epoch 565/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0678 - accuracy: 0.9886 - val_loss: 0.2112 - val_accuracy: 0.8500\n",
      "Epoch 566/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0797 - accuracy: 0.9602 - val_loss: 0.2116 - val_accuracy: 0.8500\n",
      "Epoch 567/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.0700 - accuracy: 0.9716 - val_loss: 0.2134 - val_accuracy: 0.8500\n",
      "Epoch 568/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0707 - accuracy: 0.9830 - val_loss: 0.2151 - val_accuracy: 0.8500\n",
      "Epoch 569/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0742 - accuracy: 0.9659 - val_loss: 0.2153 - val_accuracy: 0.8500\n",
      "Epoch 570/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0801 - accuracy: 0.9716 - val_loss: 0.2171 - val_accuracy: 0.8500\n",
      "Epoch 571/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0739 - accuracy: 0.9773 - val_loss: 0.2200 - val_accuracy: 0.8500\n",
      "Epoch 572/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0678 - accuracy: 0.9886 - val_loss: 0.2147 - val_accuracy: 0.8500\n",
      "Epoch 573/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0619 - accuracy: 0.9830 - val_loss: 0.2149 - val_accuracy: 0.8500\n",
      "Epoch 574/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0643 - accuracy: 0.9830 - val_loss: 0.2114 - val_accuracy: 0.8500\n",
      "Epoch 575/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0593 - accuracy: 0.9943 - val_loss: 0.2107 - val_accuracy: 0.8500\n",
      "Epoch 576/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0609 - accuracy: 0.9886 - val_loss: 0.2108 - val_accuracy: 0.8500\n",
      "Epoch 577/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.0662 - accuracy: 0.9830 - val_loss: 0.2090 - val_accuracy: 0.8500\n",
      "Epoch 578/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0581 - accuracy: 0.9943 - val_loss: 0.2104 - val_accuracy: 0.8500\n",
      "Epoch 579/1000\n",
      "176/176 [==============================] - 0s 295us/sample - loss: 0.0591 - accuracy: 0.9943 - val_loss: 0.2078 - val_accuracy: 0.8500\n",
      "Epoch 580/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.0607 - accuracy: 0.9830 - val_loss: 0.2069 - val_accuracy: 0.8500\n",
      "Epoch 581/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0603 - accuracy: 0.9830 - val_loss: 0.2134 - val_accuracy: 0.8500\n",
      "Epoch 582/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0610 - accuracy: 0.9830 - val_loss: 0.2112 - val_accuracy: 0.8500\n",
      "Epoch 583/1000\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 1.00 - 0s 114us/sample - loss: 0.0622 - accuracy: 0.9830 - val_loss: 0.2186 - val_accuracy: 0.8500\n",
      "Epoch 584/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0595 - accuracy: 0.9886 - val_loss: 0.2152 - val_accuracy: 0.8500\n",
      "Epoch 585/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.0605 - accuracy: 0.9830 - val_loss: 0.2120 - val_accuracy: 0.8500\n",
      "Epoch 586/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0608 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.8500\n",
      "Epoch 587/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0594 - accuracy: 0.9886 - val_loss: 0.2101 - val_accuracy: 0.8500\n",
      "Epoch 588/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0600 - accuracy: 0.9830 - val_loss: 0.2079 - val_accuracy: 0.8500\n",
      "Epoch 589/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0568 - accuracy: 0.9943 - val_loss: 0.2078 - val_accuracy: 0.8500\n",
      "Epoch 590/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.0578 - accuracy: 0.9943 - val_loss: 0.2063 - val_accuracy: 0.8500\n",
      "Epoch 591/1000\n",
      "176/176 [==============================] - 0s 91us/sample - loss: 0.0576 - accuracy: 0.9886 - val_loss: 0.2073 - val_accuracy: 0.8500\n",
      "Epoch 592/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0578 - accuracy: 0.9886 - val_loss: 0.2065 - val_accuracy: 0.8500\n",
      "Epoch 593/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0589 - accuracy: 0.9943 - val_loss: 0.2070 - val_accuracy: 0.8500\n",
      "Epoch 594/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0560 - accuracy: 0.9886 - val_loss: 0.2073 - val_accuracy: 0.8500\n",
      "Epoch 595/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0583 - accuracy: 0.9886 - val_loss: 0.2066 - val_accuracy: 0.8500\n",
      "Epoch 596/1000\n",
      "176/176 [==============================] - 0s 341us/sample - loss: 0.0570 - accuracy: 0.9943 - val_loss: 0.2056 - val_accuracy: 0.8500\n",
      "Epoch 597/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0558 - accuracy: 0.9886 - val_loss: 0.2056 - val_accuracy: 0.8500\n",
      "Epoch 598/1000\n",
      "176/176 [==============================] - 0s 318us/sample - loss: 0.0574 - accuracy: 0.9886 - val_loss: 0.2055 - val_accuracy: 0.8500\n",
      "Epoch 599/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0572 - accuracy: 0.9943 - val_loss: 0.2064 - val_accuracy: 0.8500\n",
      "Epoch 600/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 341us/sample - loss: 0.0612 - accuracy: 0.9830 - val_loss: 0.2052 - val_accuracy: 0.8500\n",
      "Epoch 601/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0550 - accuracy: 0.9943 - val_loss: 0.2083 - val_accuracy: 0.8500\n",
      "Epoch 602/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0597 - accuracy: 0.9943 - val_loss: 0.2074 - val_accuracy: 0.8500\n",
      "Epoch 603/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0615 - accuracy: 0.9886 - val_loss: 0.2064 - val_accuracy: 0.8500\n",
      "Epoch 604/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0612 - accuracy: 0.9830 - val_loss: 0.2069 - val_accuracy: 0.8500\n",
      "Epoch 605/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0646 - accuracy: 0.9886 - val_loss: 0.2110 - val_accuracy: 0.8500\n",
      "Epoch 606/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0513 - accuracy: 0.9886 - val_loss: 0.2169 - val_accuracy: 0.8500\n",
      "Epoch 607/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0603 - accuracy: 0.9773 - val_loss: 0.2114 - val_accuracy: 0.8500\n",
      "Epoch 608/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0639 - accuracy: 0.9716 - val_loss: 0.2080 - val_accuracy: 0.8500\n",
      "Epoch 609/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0610 - accuracy: 0.9830 - val_loss: 0.2078 - val_accuracy: 0.8500\n",
      "Epoch 610/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0535 - accuracy: 0.9943 - val_loss: 0.2113 - val_accuracy: 0.8500\n",
      "Epoch 611/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0587 - accuracy: 0.9943 - val_loss: 0.2096 - val_accuracy: 0.8500\n",
      "Epoch 612/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0558 - accuracy: 0.9943 - val_loss: 0.2081 - val_accuracy: 0.8500\n",
      "Epoch 613/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0555 - accuracy: 0.9943 - val_loss: 0.2084 - val_accuracy: 0.8500\n",
      "Epoch 614/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0592 - accuracy: 0.9830 - val_loss: 0.2071 - val_accuracy: 0.8500\n",
      "Epoch 615/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0641 - accuracy: 0.9773 - val_loss: 0.2070 - val_accuracy: 0.8500\n",
      "Epoch 616/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0599 - accuracy: 0.9773 - val_loss: 0.2074 - val_accuracy: 0.8500\n",
      "Epoch 617/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0612 - accuracy: 0.9830 - val_loss: 0.2074 - val_accuracy: 0.8500\n",
      "Epoch 618/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0639 - accuracy: 0.9830 - val_loss: 0.2059 - val_accuracy: 0.8500\n",
      "Epoch 619/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0623 - accuracy: 0.9830 - val_loss: 0.2075 - val_accuracy: 0.8500\n",
      "Epoch 620/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0532 - accuracy: 0.9943 - val_loss: 0.2074 - val_accuracy: 0.8500\n",
      "Epoch 621/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0553 - accuracy: 0.9943 - val_loss: 0.2064 - val_accuracy: 0.8500\n",
      "Epoch 622/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0522 - accuracy: 0.9943 - val_loss: 0.2073 - val_accuracy: 0.8500\n",
      "Epoch 623/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0527 - accuracy: 0.9943 - val_loss: 0.2063 - val_accuracy: 0.8500\n",
      "Epoch 624/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.0531 - accuracy: 0.9886 - val_loss: 0.2045 - val_accuracy: 0.8500\n",
      "Epoch 625/1000\n",
      "176/176 [==============================] - 0s 364us/sample - loss: 0.0531 - accuracy: 0.9943 - val_loss: 0.2020 - val_accuracy: 0.8500\n",
      "Epoch 626/1000\n",
      "176/176 [==============================] - 0s 364us/sample - loss: 0.0541 - accuracy: 0.9886 - val_loss: 0.2009 - val_accuracy: 0.8500\n",
      "Epoch 627/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0521 - accuracy: 0.9943 - val_loss: 0.2013 - val_accuracy: 0.8500\n",
      "Epoch 628/1000\n",
      "176/176 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.96 - 0s 409us/sample - loss: 0.0515 - accuracy: 0.9943 - val_loss: 0.2007 - val_accuracy: 0.8500\n",
      "Epoch 629/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0531 - accuracy: 0.9943 - val_loss: 0.2009 - val_accuracy: 0.8500\n",
      "Epoch 630/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0547 - accuracy: 0.9886 - val_loss: 0.2013 - val_accuracy: 0.8500\n",
      "Epoch 631/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0501 - accuracy: 0.9943 - val_loss: 0.2069 - val_accuracy: 0.9000\n",
      "Epoch 632/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0528 - accuracy: 0.9943 - val_loss: 0.2022 - val_accuracy: 0.8500\n",
      "Epoch 633/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0547 - accuracy: 0.9886 - val_loss: 0.2025 - val_accuracy: 0.8500\n",
      "Epoch 634/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0512 - accuracy: 0.9943 - val_loss: 0.2033 - val_accuracy: 0.8500\n",
      "Epoch 635/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0541 - accuracy: 0.9886 - val_loss: 0.2032 - val_accuracy: 0.8500\n",
      "Epoch 636/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0606 - accuracy: 0.9886 - val_loss: 0.2040 - val_accuracy: 0.8500\n",
      "Epoch 637/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0648 - accuracy: 0.9830 - val_loss: 0.2084 - val_accuracy: 0.8500\n",
      "Epoch 638/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.0681 - accuracy: 0.9602 - val_loss: 0.2134 - val_accuracy: 0.9000\n",
      "Epoch 639/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0566 - accuracy: 0.9886 - val_loss: 0.2081 - val_accuracy: 0.8500\n",
      "Epoch 640/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0681 - accuracy: 0.9716 - val_loss: 0.2061 - val_accuracy: 0.8500\n",
      "Epoch 641/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0812 - accuracy: 0.9545 - val_loss: 0.2037 - val_accuracy: 0.8500\n",
      "Epoch 642/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.1106 - accuracy: 0.9545 - val_loss: 0.2047 - val_accuracy: 0.8500\n",
      "Epoch 643/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0831 - accuracy: 0.9716 - val_loss: 0.2221 - val_accuracy: 0.8500\n",
      "Epoch 644/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0687 - accuracy: 0.9659 - val_loss: 0.2231 - val_accuracy: 0.9000\n",
      "Epoch 645/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0579 - accuracy: 0.9830 - val_loss: 0.2154 - val_accuracy: 0.8500\n",
      "Epoch 646/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0527 - accuracy: 0.9886 - val_loss: 0.2159 - val_accuracy: 0.9000\n",
      "Epoch 647/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0521 - accuracy: 0.9943 - val_loss: 0.2038 - val_accuracy: 0.8500\n",
      "Epoch 648/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0560 - accuracy: 0.9830 - val_loss: 0.2021 - val_accuracy: 0.8500\n",
      "Epoch 649/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0564 - accuracy: 0.9886 - val_loss: 0.2095 - val_accuracy: 0.9000\n",
      "Epoch 650/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0494 - accuracy: 0.9943 - val_loss: 0.2053 - val_accuracy: 0.8500\n",
      "Epoch 651/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0487 - accuracy: 0.9886 - val_loss: 0.2063 - val_accuracy: 0.8500\n",
      "Epoch 652/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0558 - accuracy: 0.9943 - val_loss: 0.2057 - val_accuracy: 0.8500\n",
      "Epoch 653/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0492 - accuracy: 0.9943 - val_loss: 0.2058 - val_accuracy: 0.8500\n",
      "Epoch 654/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0539 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.8500\n",
      "Epoch 655/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0668 - accuracy: 0.9773 - val_loss: 0.2030 - val_accuracy: 0.8500\n",
      "Epoch 656/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0555 - accuracy: 0.9886 - val_loss: 0.2119 - val_accuracy: 0.9000\n",
      "Epoch 657/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0463 - accuracy: 0.9943 - val_loss: 0.2118 - val_accuracy: 0.8500\n",
      "Epoch 658/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0537 - accuracy: 0.9830 - val_loss: 0.2074 - val_accuracy: 0.8500\n",
      "Epoch 659/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0606 - accuracy: 0.9943 - val_loss: 0.2031 - val_accuracy: 0.8500\n",
      "Epoch 660/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0506 - accuracy: 0.9943 - val_loss: 0.2024 - val_accuracy: 0.8500\n",
      "Epoch 661/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0475 - accuracy: 0.9943 - val_loss: 0.2039 - val_accuracy: 0.8500\n",
      "Epoch 662/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0474 - accuracy: 0.9943 - val_loss: 0.2009 - val_accuracy: 0.8500\n",
      "Epoch 663/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.0485 - accuracy: 0.9943 - val_loss: 0.1999 - val_accuracy: 0.8500\n",
      "Epoch 664/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0474 - accuracy: 0.9943 - val_loss: 0.2024 - val_accuracy: 0.9000\n",
      "Epoch 665/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0499 - accuracy: 0.9886 - val_loss: 0.1999 - val_accuracy: 0.8500\n",
      "Epoch 666/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0546 - accuracy: 0.9943 - val_loss: 0.1997 - val_accuracy: 0.8500\n",
      "Epoch 667/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0472 - accuracy: 0.9943 - val_loss: 0.2003 - val_accuracy: 0.8500\n",
      "Epoch 668/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0474 - accuracy: 0.9943 - val_loss: 0.2006 - val_accuracy: 0.8500\n",
      "Epoch 669/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0470 - accuracy: 0.9943 - val_loss: 0.2002 - val_accuracy: 0.8500\n",
      "Epoch 670/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0500 - accuracy: 0.9943 - val_loss: 0.1992 - val_accuracy: 0.8500\n",
      "Epoch 671/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0472 - accuracy: 0.9943 - val_loss: 0.1992 - val_accuracy: 0.8500\n",
      "Epoch 672/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0475 - accuracy: 0.9943 - val_loss: 0.1997 - val_accuracy: 0.8500\n",
      "Epoch 673/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0471 - accuracy: 0.9943 - val_loss: 0.2013 - val_accuracy: 0.8500\n",
      "Epoch 674/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0473 - accuracy: 0.9943 - val_loss: 0.1994 - val_accuracy: 0.8500\n",
      "Epoch 675/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0476 - accuracy: 0.9943 - val_loss: 0.1996 - val_accuracy: 0.8500\n",
      "Epoch 676/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0472 - accuracy: 0.9943 - val_loss: 0.2001 - val_accuracy: 0.8500\n",
      "Epoch 677/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0526 - accuracy: 0.9886 - val_loss: 0.1996 - val_accuracy: 0.8500\n",
      "Epoch 678/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9000\n",
      "Epoch 679/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.2028 - val_accuracy: 0.8500\n",
      "Epoch 680/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0522 - accuracy: 0.9886 - val_loss: 0.2010 - val_accuracy: 0.8500\n",
      "Epoch 681/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0531 - accuracy: 0.9943 - val_loss: 0.2005 - val_accuracy: 0.8500\n",
      "Epoch 682/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0583 - accuracy: 0.9886 - val_loss: 0.2004 - val_accuracy: 0.8500\n",
      "Epoch 683/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0523 - accuracy: 0.9943 - val_loss: 0.2035 - val_accuracy: 0.9000\n",
      "Epoch 684/1000\n",
      "176/176 [==============================] - 0s 205us/sample - loss: 0.0513 - accuracy: 0.9886 - val_loss: 0.2003 - val_accuracy: 0.8500\n",
      "Epoch 685/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0472 - accuracy: 0.9943 - val_loss: 0.2022 - val_accuracy: 0.8500\n",
      "Epoch 686/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0452 - accuracy: 0.9943 - val_loss: 0.2000 - val_accuracy: 0.8500\n",
      "Epoch 687/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0476 - accuracy: 0.9943 - val_loss: 0.2013 - val_accuracy: 0.8500\n",
      "Epoch 688/1000\n",
      "176/176 [==============================] - 0s 273us/sample - loss: 0.0473 - accuracy: 0.9943 - val_loss: 0.2000 - val_accuracy: 0.8500\n",
      "Epoch 689/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0460 - accuracy: 0.9943 - val_loss: 0.1993 - val_accuracy: 0.8500\n",
      "Epoch 690/1000\n",
      "176/176 [==============================] - 0s 545us/sample - loss: 0.0461 - accuracy: 0.9943 - val_loss: 0.1987 - val_accuracy: 0.8500\n",
      "Epoch 691/1000\n",
      "176/176 [==============================] - 0s 477us/sample - loss: 0.0446 - accuracy: 0.9943 - val_loss: 0.1986 - val_accuracy: 0.8500\n",
      "Epoch 692/1000\n",
      "176/176 [==============================] - 0s 523us/sample - loss: 0.0477 - accuracy: 0.9943 - val_loss: 0.1977 - val_accuracy: 0.8500\n",
      "Epoch 693/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0435 - accuracy: 0.9943 - val_loss: 0.2002 - val_accuracy: 0.8500\n",
      "Epoch 694/1000\n",
      "176/176 [==============================] - 0s 215us/sample - loss: 0.0464 - accuracy: 0.9943 - val_loss: 0.2006 - val_accuracy: 0.9000\n",
      "Epoch 695/1000\n",
      "176/176 [==============================] - 0s 613us/sample - loss: 0.0481 - accuracy: 0.9943 - val_loss: 0.1970 - val_accuracy: 0.8500\n",
      "Epoch 696/1000\n",
      "176/176 [==============================] - 0s 250us/sample - loss: 0.0456 - accuracy: 0.9943 - val_loss: 0.1998 - val_accuracy: 0.9000\n",
      "Epoch 697/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0454 - accuracy: 0.9943 - val_loss: 0.1977 - val_accuracy: 0.8500\n",
      "Epoch 698/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0440 - accuracy: 0.9943 - val_loss: 0.2023 - val_accuracy: 0.9000\n",
      "Epoch 699/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0432 - accuracy: 1.0000 - val_loss: 0.1988 - val_accuracy: 0.8500\n",
      "Epoch 700/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0498 - accuracy: 0.9943 - val_loss: 0.1997 - val_accuracy: 0.9000\n",
      "Epoch 701/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0427 - accuracy: 0.9943 - val_loss: 0.1974 - val_accuracy: 0.8500\n",
      "Epoch 702/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0455 - accuracy: 0.9943 - val_loss: 0.1982 - val_accuracy: 0.8500\n",
      "Epoch 703/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0442 - accuracy: 0.9943 - val_loss: 0.1975 - val_accuracy: 0.8500\n",
      "Epoch 704/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0468 - accuracy: 0.9886 - val_loss: 0.1977 - val_accuracy: 0.8500\n",
      "Epoch 705/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0434 - accuracy: 0.9943 - val_loss: 0.1973 - val_accuracy: 0.8500\n",
      "Epoch 706/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0430 - accuracy: 0.9943 - val_loss: 0.1988 - val_accuracy: 0.8500\n",
      "Epoch 707/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0530 - accuracy: 0.9886 - val_loss: 0.1998 - val_accuracy: 0.9000\n",
      "Epoch 708/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.1997 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 709/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0460 - accuracy: 0.9943 - val_loss: 0.1993 - val_accuracy: 0.8500\n",
      "Epoch 710/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0443 - accuracy: 0.9943 - val_loss: 0.1978 - val_accuracy: 0.8500\n",
      "Epoch 711/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0446 - accuracy: 0.9943 - val_loss: 0.1982 - val_accuracy: 0.9000\n",
      "Epoch 712/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.0431 - accuracy: 0.9943 - val_loss: 0.1956 - val_accuracy: 0.9000\n",
      "Epoch 713/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.0424 - accuracy: 0.9943 - val_loss: 0.1949 - val_accuracy: 0.8500\n",
      "Epoch 714/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0428 - accuracy: 0.9943 - val_loss: 0.1955 - val_accuracy: 0.9000\n",
      "Epoch 715/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0435 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9000\n",
      "Epoch 716/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0504 - accuracy: 0.9886 - val_loss: 0.1955 - val_accuracy: 0.8500\n",
      "Epoch 717/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0551 - accuracy: 0.9830 - val_loss: 0.1953 - val_accuracy: 0.9000\n",
      "Epoch 718/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.0478 - accuracy: 0.9943 - val_loss: 0.1946 - val_accuracy: 0.8500\n",
      "Epoch 719/1000\n",
      "176/176 [==============================] - 0s 122us/sample - loss: 0.0409 - accuracy: 0.9943 - val_loss: 0.1995 - val_accuracy: 0.9000\n",
      "Epoch 720/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0435 - accuracy: 0.9943 - val_loss: 0.1965 - val_accuracy: 0.8500\n",
      "Epoch 721/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0528 - accuracy: 0.9886 - val_loss: 0.1938 - val_accuracy: 0.9000\n",
      "Epoch 722/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0458 - accuracy: 0.9886 - val_loss: 0.1949 - val_accuracy: 0.8500\n",
      "Epoch 723/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0453 - accuracy: 0.9943 - val_loss: 0.1967 - val_accuracy: 0.9000\n",
      "Epoch 724/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.0438 - accuracy: 0.9943 - val_loss: 0.1932 - val_accuracy: 0.8500\n",
      "Epoch 725/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0453 - accuracy: 0.9943 - val_loss: 0.1955 - val_accuracy: 0.9000\n",
      "Epoch 726/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0410 - accuracy: 0.9943 - val_loss: 0.1947 - val_accuracy: 0.8500\n",
      "Epoch 727/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0483 - accuracy: 0.9943 - val_loss: 0.1956 - val_accuracy: 0.8500\n",
      "Epoch 728/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0456 - accuracy: 0.9943 - val_loss: 0.1965 - val_accuracy: 0.8500\n",
      "Epoch 729/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.1973 - val_accuracy: 0.9000\n",
      "Epoch 730/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0414 - accuracy: 0.9943 - val_loss: 0.1961 - val_accuracy: 0.8500\n",
      "Epoch 731/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0555 - accuracy: 0.9886 - val_loss: 0.1960 - val_accuracy: 0.8500\n",
      "Epoch 732/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0504 - accuracy: 0.9886 - val_loss: 0.1956 - val_accuracy: 0.8500\n",
      "Epoch 733/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.9000\n",
      "Epoch 734/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0464 - accuracy: 0.9943 - val_loss: 0.1932 - val_accuracy: 0.8500\n",
      "Epoch 735/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0438 - accuracy: 0.9943 - val_loss: 0.1937 - val_accuracy: 0.9000\n",
      "Epoch 736/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0396 - accuracy: 0.9943 - val_loss: 0.1953 - val_accuracy: 0.8500\n",
      "Epoch 737/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0455 - accuracy: 0.9943 - val_loss: 0.1941 - val_accuracy: 0.9000\n",
      "Epoch 738/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0427 - accuracy: 0.9943 - val_loss: 0.1944 - val_accuracy: 0.9000\n",
      "Epoch 739/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0393 - accuracy: 0.9943 - val_loss: 0.1949 - val_accuracy: 0.9000\n",
      "Epoch 740/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0450 - accuracy: 0.9943 - val_loss: 0.1945 - val_accuracy: 0.9000\n",
      "Epoch 741/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0407 - accuracy: 0.9943 - val_loss: 0.1988 - val_accuracy: 0.9000\n",
      "Epoch 742/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.1954 - val_accuracy: 0.8500\n",
      "Epoch 743/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0399 - accuracy: 0.9943 - val_loss: 0.1955 - val_accuracy: 0.8500\n",
      "Epoch 744/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.0459 - accuracy: 0.9943 - val_loss: 0.1949 - val_accuracy: 0.8500\n",
      "Epoch 745/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0398 - accuracy: 0.9943 - val_loss: 0.1946 - val_accuracy: 0.8500\n",
      "Epoch 746/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0406 - accuracy: 0.9943 - val_loss: 0.1961 - val_accuracy: 0.9000\n",
      "Epoch 747/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0380 - accuracy: 0.9943 - val_loss: 0.1952 - val_accuracy: 0.8500\n",
      "Epoch 748/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0401 - accuracy: 0.9943 - val_loss: 0.1967 - val_accuracy: 0.9000\n",
      "Epoch 749/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0485 - accuracy: 0.9943 - val_loss: 0.1937 - val_accuracy: 0.8500\n",
      "Epoch 750/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0445 - accuracy: 0.9830 - val_loss: 0.1936 - val_accuracy: 0.9000\n",
      "Epoch 751/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0381 - accuracy: 1.0000 - val_loss: 0.1975 - val_accuracy: 0.9000\n",
      "Epoch 752/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0391 - accuracy: 0.9943 - val_loss: 0.1948 - val_accuracy: 0.9000\n",
      "Epoch 753/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0418 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.8500\n",
      "Epoch 754/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0393 - accuracy: 0.9943 - val_loss: 0.1948 - val_accuracy: 0.8500\n",
      "Epoch 755/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0401 - accuracy: 0.9943 - val_loss: 0.1983 - val_accuracy: 0.9000\n",
      "Epoch 756/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.1944 - val_accuracy: 0.8500\n",
      "Epoch 757/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0404 - accuracy: 0.9943 - val_loss: 0.1946 - val_accuracy: 0.9000\n",
      "Epoch 758/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0377 - accuracy: 0.9943 - val_loss: 0.1957 - val_accuracy: 0.9000\n",
      "Epoch 759/1000\n",
      "176/176 [==============================] - 0s 114us/sample - loss: 0.0404 - accuracy: 0.9943 - val_loss: 0.1972 - val_accuracy: 0.9000\n",
      "Epoch 760/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.0472 - accuracy: 0.9886 - val_loss: 0.1916 - val_accuracy: 0.8500\n",
      "Epoch 761/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.0634 - accuracy: 0.9659 - val_loss: 0.1916 - val_accuracy: 0.9000\n",
      "Epoch 762/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0534 - accuracy: 0.9773 - val_loss: 0.1921 - val_accuracy: 0.9000\n",
      "Epoch 763/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0398 - accuracy: 0.9943 - val_loss: 0.1931 - val_accuracy: 0.8500\n",
      "Epoch 764/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0373 - accuracy: 0.9943 - val_loss: 0.1973 - val_accuracy: 0.9000\n",
      "Epoch 765/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 0.8500\n",
      "Epoch 766/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0403 - accuracy: 0.9943 - val_loss: 0.1949 - val_accuracy: 0.9000\n",
      "Epoch 767/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0375 - accuracy: 0.9943 - val_loss: 0.1944 - val_accuracy: 0.9000\n",
      "Epoch 768/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0379 - accuracy: 0.9943 - val_loss: 0.1936 - val_accuracy: 0.8500\n",
      "Epoch 769/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0372 - accuracy: 0.9943 - val_loss: 0.1933 - val_accuracy: 0.8500\n",
      "Epoch 770/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0368 - accuracy: 0.9943 - val_loss: 0.1946 - val_accuracy: 0.9000\n",
      "Epoch 771/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0389 - accuracy: 0.9943 - val_loss: 0.1939 - val_accuracy: 0.8500\n",
      "Epoch 772/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0382 - accuracy: 0.9943 - val_loss: 0.1923 - val_accuracy: 0.8500\n",
      "Epoch 773/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0412 - accuracy: 0.9943 - val_loss: 0.1966 - val_accuracy: 0.9000\n",
      "Epoch 774/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.1923 - val_accuracy: 0.9000\n",
      "Epoch 775/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.0410 - accuracy: 0.9943 - val_loss: 0.1913 - val_accuracy: 0.8500\n",
      "Epoch 776/1000\n",
      "176/176 [==============================] - 0s 250us/sample - loss: 0.0368 - accuracy: 0.9943 - val_loss: 0.1954 - val_accuracy: 0.9000\n",
      "Epoch 777/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0416 - accuracy: 0.9943 - val_loss: 0.1929 - val_accuracy: 0.9000\n",
      "Epoch 778/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0369 - accuracy: 0.9943 - val_loss: 0.1932 - val_accuracy: 0.9000\n",
      "Epoch 779/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0369 - accuracy: 0.9943 - val_loss: 0.1934 - val_accuracy: 0.9000\n",
      "Epoch 780/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0374 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.8500\n",
      "Epoch 781/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0358 - accuracy: 0.9943 - val_loss: 0.1944 - val_accuracy: 0.9000\n",
      "Epoch 782/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.1933 - val_accuracy: 0.8500\n",
      "Epoch 783/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0422 - accuracy: 0.9943 - val_loss: 0.1949 - val_accuracy: 0.9000\n",
      "Epoch 784/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0359 - accuracy: 0.9943 - val_loss: 0.1971 - val_accuracy: 0.9000\n",
      "Epoch 785/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0364 - accuracy: 1.0000 - val_loss: 0.1934 - val_accuracy: 0.8500\n",
      "Epoch 786/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0361 - accuracy: 0.9943 - val_loss: 0.1930 - val_accuracy: 0.9000\n",
      "Epoch 787/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0382 - accuracy: 0.9943 - val_loss: 0.1957 - val_accuracy: 0.9000\n",
      "Epoch 788/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9000\n",
      "Epoch 789/1000\n",
      "176/176 [==============================] - 0s 432us/sample - loss: 0.0350 - accuracy: 0.9943 - val_loss: 0.1910 - val_accuracy: 0.9000\n",
      "Epoch 790/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0367 - accuracy: 0.9943 - val_loss: 0.1934 - val_accuracy: 0.9000\n",
      "Epoch 791/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0342 - accuracy: 0.9943 - val_loss: 0.1928 - val_accuracy: 0.8500\n",
      "Epoch 792/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0378 - accuracy: 0.9943 - val_loss: 0.1942 - val_accuracy: 0.9000\n",
      "Epoch 793/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0449 - accuracy: 0.9886 - val_loss: 0.1920 - val_accuracy: 0.9000\n",
      "Epoch 794/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0363 - accuracy: 0.9943 - val_loss: 0.1935 - val_accuracy: 0.8500\n",
      "Epoch 795/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0341 - accuracy: 0.9943 - val_loss: 0.2014 - val_accuracy: 0.9000\n",
      "Epoch 796/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.8500\n",
      "Epoch 797/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0368 - accuracy: 0.9943 - val_loss: 0.1934 - val_accuracy: 0.9000\n",
      "Epoch 798/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 0.9000\n",
      "Epoch 799/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0350 - accuracy: 0.9943 - val_loss: 0.1933 - val_accuracy: 0.9000\n",
      "Epoch 800/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0363 - accuracy: 0.9943 - val_loss: 0.1922 - val_accuracy: 0.9000\n",
      "Epoch 801/1000\n",
      "176/176 [==============================] - 0s 477us/sample - loss: 0.0345 - accuracy: 0.9943 - val_loss: 0.1907 - val_accuracy: 0.9000\n",
      "Epoch 802/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0339 - accuracy: 0.9943 - val_loss: 0.1907 - val_accuracy: 0.9000\n",
      "Epoch 803/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.0357 - accuracy: 0.9943 - val_loss: 0.1905 - val_accuracy: 0.9000\n",
      "Epoch 804/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0357 - accuracy: 0.9943 - val_loss: 0.1915 - val_accuracy: 0.9000\n",
      "Epoch 805/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0381 - accuracy: 0.9943 - val_loss: 0.1940 - val_accuracy: 0.9000\n",
      "Epoch 806/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0348 - accuracy: 0.9943 - val_loss: 0.1915 - val_accuracy: 0.9000\n",
      "Epoch 807/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0342 - accuracy: 0.9943 - val_loss: 0.1929 - val_accuracy: 0.9000\n",
      "Epoch 808/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.1912 - val_accuracy: 0.9000\n",
      "Epoch 809/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0352 - accuracy: 0.9943 - val_loss: 0.1910 - val_accuracy: 0.9000\n",
      "Epoch 810/1000\n",
      "176/176 [==============================] - 0s 454us/sample - loss: 0.0387 - accuracy: 1.0000 - val_loss: 0.1900 - val_accuracy: 0.8500\n",
      "Epoch 811/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.0378 - accuracy: 0.9943 - val_loss: 0.1888 - val_accuracy: 0.9000\n",
      "Epoch 812/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0344 - accuracy: 0.9943 - val_loss: 0.1891 - val_accuracy: 0.9000\n",
      "Epoch 813/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0336 - accuracy: 0.9943 - val_loss: 0.1891 - val_accuracy: 0.9000\n",
      "Epoch 814/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.0330 - accuracy: 0.9943 - val_loss: 0.1888 - val_accuracy: 0.9000\n",
      "Epoch 815/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0362 - accuracy: 0.9943 - val_loss: 0.1917 - val_accuracy: 0.9000\n",
      "Epoch 816/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9000\n",
      "Epoch 817/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.0332 - accuracy: 0.9943 - val_loss: 0.1886 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 818/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9000\n",
      "Epoch 819/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0412 - accuracy: 0.9943 - val_loss: 0.1891 - val_accuracy: 0.9000\n",
      "Epoch 820/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9000\n",
      "Epoch 821/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0357 - accuracy: 0.9943 - val_loss: 0.1914 - val_accuracy: 0.8500\n",
      "Epoch 822/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0405 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9000\n",
      "Epoch 823/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0355 - accuracy: 0.9943 - val_loss: 0.1908 - val_accuracy: 0.8500\n",
      "Epoch 824/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0349 - accuracy: 0.9943 - val_loss: 0.1992 - val_accuracy: 0.9000\n",
      "Epoch 825/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0347 - accuracy: 0.9943 - val_loss: 0.1892 - val_accuracy: 0.9000\n",
      "Epoch 826/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0333 - accuracy: 0.9943 - val_loss: 0.1956 - val_accuracy: 0.9000\n",
      "Epoch 827/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0361 - accuracy: 0.9943 - val_loss: 0.1905 - val_accuracy: 0.9000\n",
      "Epoch 828/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0451 - accuracy: 0.9943 - val_loss: 0.1903 - val_accuracy: 0.8500\n",
      "Epoch 829/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0391 - accuracy: 0.9943 - val_loss: 0.1900 - val_accuracy: 0.9000\n",
      "Epoch 830/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9000\n",
      "Epoch 831/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0322 - accuracy: 0.9943 - val_loss: 0.1891 - val_accuracy: 0.9000\n",
      "Epoch 832/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0366 - accuracy: 0.9943 - val_loss: 0.1905 - val_accuracy: 0.9000\n",
      "Epoch 833/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0305 - accuracy: 0.9943 - val_loss: 0.1930 - val_accuracy: 0.8500\n",
      "Epoch 834/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0331 - accuracy: 0.9943 - val_loss: 0.2008 - val_accuracy: 0.9000\n",
      "Epoch 835/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0390 - accuracy: 0.9943 - val_loss: 0.1931 - val_accuracy: 0.8500\n",
      "Epoch 836/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0405 - accuracy: 0.9943 - val_loss: 0.1970 - val_accuracy: 0.9000\n",
      "Epoch 837/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0432 - accuracy: 0.9943 - val_loss: 0.1901 - val_accuracy: 0.9000\n",
      "Epoch 838/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0343 - accuracy: 0.9943 - val_loss: 0.1894 - val_accuracy: 0.9000\n",
      "Epoch 839/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0315 - accuracy: 0.9943 - val_loss: 0.1951 - val_accuracy: 0.9000\n",
      "Epoch 840/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0328 - accuracy: 0.9943 - val_loss: 0.1898 - val_accuracy: 0.9000\n",
      "Epoch 841/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.1904 - val_accuracy: 0.9000\n",
      "Epoch 842/1000\n",
      "176/176 [==============================] - 0s 477us/sample - loss: 0.0310 - accuracy: 0.9943 - val_loss: 0.1870 - val_accuracy: 0.9000\n",
      "Epoch 843/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0325 - accuracy: 0.9943 - val_loss: 0.1899 - val_accuracy: 0.9000\n",
      "Epoch 844/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.0319 - accuracy: 0.9943 - val_loss: 0.1862 - val_accuracy: 0.9000\n",
      "Epoch 845/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0328 - accuracy: 0.9943 - val_loss: 0.1866 - val_accuracy: 0.9000\n",
      "Epoch 846/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0386 - accuracy: 0.9943 - val_loss: 0.1914 - val_accuracy: 0.9000\n",
      "Epoch 847/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0467 - accuracy: 0.9886 - val_loss: 0.1878 - val_accuracy: 0.9000\n",
      "Epoch 848/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0412 - accuracy: 0.9886 - val_loss: 0.1868 - val_accuracy: 0.9000\n",
      "Epoch 849/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0470 - accuracy: 0.9830 - val_loss: 0.1921 - val_accuracy: 0.9000\n",
      "Epoch 850/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0390 - accuracy: 0.9943 - val_loss: 0.1890 - val_accuracy: 0.9000\n",
      "Epoch 851/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9000\n",
      "Epoch 852/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 0.8500\n",
      "Epoch 853/1000\n",
      "176/176 [==============================] - 0s 205us/sample - loss: 0.0367 - accuracy: 0.9943 - val_loss: 0.1905 - val_accuracy: 0.9000\n",
      "Epoch 854/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0338 - accuracy: 0.9943 - val_loss: 0.1863 - val_accuracy: 0.9000\n",
      "Epoch 855/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.1935 - val_accuracy: 0.9000\n",
      "Epoch 856/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.0309 - accuracy: 0.9943 - val_loss: 0.1869 - val_accuracy: 0.9000\n",
      "Epoch 857/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0308 - accuracy: 0.9943 - val_loss: 0.1873 - val_accuracy: 0.9000\n",
      "Epoch 858/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0297 - accuracy: 0.9943 - val_loss: 0.1885 - val_accuracy: 0.9000\n",
      "Epoch 859/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.1894 - val_accuracy: 0.9000\n",
      "Epoch 860/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0316 - accuracy: 0.9943 - val_loss: 0.1886 - val_accuracy: 0.9000\n",
      "Epoch 861/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9000\n",
      "Epoch 862/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0362 - accuracy: 0.9943 - val_loss: 0.1884 - val_accuracy: 0.9000\n",
      "Epoch 863/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0395 - accuracy: 0.9886 - val_loss: 0.1920 - val_accuracy: 0.9000\n",
      "Epoch 864/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0282 - accuracy: 0.9943 - val_loss: 0.1910 - val_accuracy: 0.8500\n",
      "Epoch 865/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0310 - accuracy: 0.9943 - val_loss: 0.1965 - val_accuracy: 0.9000\n",
      "Epoch 866/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9000\n",
      "Epoch 867/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0325 - accuracy: 0.9943 - val_loss: 0.1887 - val_accuracy: 0.9000\n",
      "Epoch 868/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9000\n",
      "Epoch 869/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0302 - accuracy: 0.9943 - val_loss: 0.1914 - val_accuracy: 0.9000\n",
      "Epoch 870/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0365 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9000\n",
      "Epoch 871/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0319 - accuracy: 0.9943 - val_loss: 0.1886 - val_accuracy: 0.9000\n",
      "Epoch 872/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9000\n",
      "Epoch 873/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0295 - accuracy: 0.9943 - val_loss: 0.1862 - val_accuracy: 0.9000\n",
      "Epoch 874/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0290 - accuracy: 0.9943 - val_loss: 0.1903 - val_accuracy: 0.9000\n",
      "Epoch 875/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9000\n",
      "Epoch 876/1000\n",
      "176/176 [==============================] - 0s 409us/sample - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.1838 - val_accuracy: 0.9000\n",
      "Epoch 877/1000\n",
      "176/176 [==============================] - 0s 386us/sample - loss: 0.0312 - accuracy: 0.9943 - val_loss: 0.1836 - val_accuracy: 0.9000\n",
      "Epoch 878/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.1840 - val_accuracy: 0.9000\n",
      "Epoch 879/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.0320 - accuracy: 0.9943 - val_loss: 0.1875 - val_accuracy: 0.9000\n",
      "Epoch 880/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0476 - accuracy: 0.9830 - val_loss: 0.1840 - val_accuracy: 0.9000\n",
      "Epoch 881/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0517 - accuracy: 0.9886 - val_loss: 0.1892 - val_accuracy: 0.9000\n",
      "Epoch 882/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9000\n",
      "Epoch 883/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0303 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9000\n",
      "Epoch 884/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0362 - accuracy: 0.9886 - val_loss: 0.1871 - val_accuracy: 0.9000\n",
      "Epoch 885/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0338 - accuracy: 0.9943 - val_loss: 0.1892 - val_accuracy: 0.9000\n",
      "Epoch 886/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9000\n",
      "Epoch 887/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0297 - accuracy: 0.9943 - val_loss: 0.1875 - val_accuracy: 0.9000\n",
      "Epoch 888/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0341 - accuracy: 0.9943 - val_loss: 0.1877 - val_accuracy: 0.9000\n",
      "Epoch 889/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0295 - accuracy: 0.9943 - val_loss: 0.1877 - val_accuracy: 0.9000\n",
      "Epoch 890/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 0.9000\n",
      "Epoch 891/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9000\n",
      "Epoch 892/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0302 - accuracy: 0.9943 - val_loss: 0.1901 - val_accuracy: 0.9000\n",
      "Epoch 893/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9000\n",
      "Epoch 894/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0296 - accuracy: 0.9943 - val_loss: 0.1886 - val_accuracy: 0.9000\n",
      "Epoch 895/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0376 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9000\n",
      "Epoch 896/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0387 - accuracy: 0.9943 - val_loss: 0.1978 - val_accuracy: 0.9000\n",
      "Epoch 897/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.1871 - val_accuracy: 0.9000\n",
      "Epoch 898/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0285 - accuracy: 0.9943 - val_loss: 0.1902 - val_accuracy: 0.9000\n",
      "Epoch 899/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0282 - accuracy: 0.9943 - val_loss: 0.1872 - val_accuracy: 0.9000\n",
      "Epoch 900/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9000\n",
      "Epoch 901/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0277 - accuracy: 0.9943 - val_loss: 0.1876 - val_accuracy: 0.9000\n",
      "Epoch 902/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.1915 - val_accuracy: 0.9000\n",
      "Epoch 903/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0295 - accuracy: 0.9943 - val_loss: 0.1880 - val_accuracy: 0.9000\n",
      "Epoch 904/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0277 - accuracy: 0.9943 - val_loss: 0.1929 - val_accuracy: 0.9000\n",
      "Epoch 905/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0290 - accuracy: 0.9943 - val_loss: 0.1888 - val_accuracy: 0.9000\n",
      "Epoch 906/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9000\n",
      "Epoch 907/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9000\n",
      "Epoch 908/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0295 - accuracy: 0.9943 - val_loss: 0.1903 - val_accuracy: 0.9000\n",
      "Epoch 909/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.1902 - val_accuracy: 0.9000\n",
      "Epoch 910/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0261 - accuracy: 0.9943 - val_loss: 0.1882 - val_accuracy: 0.9000\n",
      "Epoch 911/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.1941 - val_accuracy: 0.9000\n",
      "Epoch 912/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0282 - accuracy: 0.9943 - val_loss: 0.1881 - val_accuracy: 0.9000\n",
      "Epoch 913/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0263 - accuracy: 0.9943 - val_loss: 0.1913 - val_accuracy: 0.9000\n",
      "Epoch 914/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.8500\n",
      "Epoch 915/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0298 - accuracy: 0.9943 - val_loss: 0.1896 - val_accuracy: 0.9000\n",
      "Epoch 916/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0283 - accuracy: 0.9943 - val_loss: 0.1903 - val_accuracy: 0.9000\n",
      "Epoch 917/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9000\n",
      "Epoch 918/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0311 - accuracy: 0.9943 - val_loss: 0.1942 - val_accuracy: 0.9000\n",
      "Epoch 919/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0344 - accuracy: 0.9943 - val_loss: 0.1903 - val_accuracy: 0.8500\n",
      "Epoch 920/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0363 - accuracy: 0.9943 - val_loss: 0.1968 - val_accuracy: 0.9000\n",
      "Epoch 921/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9000\n",
      "Epoch 922/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9000\n",
      "Epoch 923/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0315 - accuracy: 0.9943 - val_loss: 0.1890 - val_accuracy: 0.9000\n",
      "Epoch 924/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0283 - accuracy: 0.9943 - val_loss: 0.1874 - val_accuracy: 0.9000\n",
      "Epoch 925/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9000\n",
      "Epoch 926/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 927/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0264 - accuracy: 0.9943 - val_loss: 0.1894 - val_accuracy: 0.9000\n",
      "Epoch 928/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9000\n",
      "Epoch 929/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.1862 - val_accuracy: 0.9000\n",
      "Epoch 930/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0268 - accuracy: 0.9943 - val_loss: 0.1880 - val_accuracy: 0.9000\n",
      "Epoch 931/1000\n",
      "176/176 [==============================] - 0s 205us/sample - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9000\n",
      "Epoch 932/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.1848 - val_accuracy: 0.9000\n",
      "Epoch 933/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0280 - accuracy: 0.9943 - val_loss: 0.1858 - val_accuracy: 0.9000\n",
      "Epoch 934/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.1857 - val_accuracy: 0.9000\n",
      "Epoch 935/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0257 - accuracy: 0.9943 - val_loss: 0.1882 - val_accuracy: 0.9000\n",
      "Epoch 936/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9000\n",
      "Epoch 937/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0268 - accuracy: 0.9943 - val_loss: 0.1894 - val_accuracy: 0.9000\n",
      "Epoch 938/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9000\n",
      "Epoch 939/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0297 - accuracy: 0.9943 - val_loss: 0.1872 - val_accuracy: 0.9000\n",
      "Epoch 940/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 0.9000\n",
      "Epoch 941/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.0266 - accuracy: 0.9943 - val_loss: 0.1871 - val_accuracy: 0.9000\n",
      "Epoch 942/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9000\n",
      "Epoch 943/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0262 - accuracy: 0.9943 - val_loss: 0.1883 - val_accuracy: 0.9000\n",
      "Epoch 944/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9000\n",
      "Epoch 945/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.1864 - val_accuracy: 0.9000\n",
      "Epoch 946/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9000\n",
      "Epoch 947/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0256 - accuracy: 0.9943 - val_loss: 0.1881 - val_accuracy: 0.9000\n",
      "Epoch 948/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9000\n",
      "Epoch 949/1000\n",
      "176/176 [==============================] - 0s 205us/sample - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.1869 - val_accuracy: 0.9000\n",
      "Epoch 950/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0277 - accuracy: 0.9943 - val_loss: 0.1891 - val_accuracy: 0.9000\n",
      "Epoch 951/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 0.9000\n",
      "Epoch 952/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0341 - accuracy: 0.9943 - val_loss: 0.1875 - val_accuracy: 0.9000\n",
      "Epoch 953/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0462 - accuracy: 0.9830 - val_loss: 0.1865 - val_accuracy: 0.9000\n",
      "Epoch 954/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0327 - accuracy: 0.9943 - val_loss: 0.1861 - val_accuracy: 0.9000\n",
      "Epoch 955/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0281 - accuracy: 0.9943 - val_loss: 0.2031 - val_accuracy: 0.9500\n",
      "Epoch 956/1000\n",
      "176/176 [==============================] - 0s 205us/sample - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9000\n",
      "Epoch 957/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0291 - accuracy: 0.9943 - val_loss: 0.1910 - val_accuracy: 0.9000\n",
      "Epoch 958/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9000\n",
      "Epoch 959/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9000\n",
      "Epoch 960/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9000\n",
      "Epoch 961/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.1844 - val_accuracy: 0.9000\n",
      "Epoch 962/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.1931 - val_accuracy: 0.9000\n",
      "Epoch 963/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0267 - accuracy: 0.9943 - val_loss: 0.1853 - val_accuracy: 0.9000\n",
      "Epoch 964/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9000\n",
      "Epoch 965/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0241 - accuracy: 0.9943 - val_loss: 0.1863 - val_accuracy: 0.9000\n",
      "Epoch 966/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.1867 - val_accuracy: 0.9000\n",
      "Epoch 967/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9000\n",
      "Epoch 968/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9000\n",
      "Epoch 969/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0253 - accuracy: 0.9943 - val_loss: 0.1930 - val_accuracy: 0.9000\n",
      "Epoch 970/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9000\n",
      "Epoch 971/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9000\n",
      "Epoch 972/1000\n",
      "176/176 [==============================] - 0s 204us/sample - loss: 0.0269 - accuracy: 0.9943 - val_loss: 0.1865 - val_accuracy: 0.9000\n",
      "Epoch 973/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.1863 - val_accuracy: 0.9000\n",
      "Epoch 974/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0276 - accuracy: 0.9943 - val_loss: 0.1872 - val_accuracy: 0.9000\n",
      "Epoch 975/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1968 - val_accuracy: 0.9000\n",
      "Epoch 976/1000\n",
      "176/176 [==============================] - 0s 182us/sample - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.1851 - val_accuracy: 0.9000\n",
      "Epoch 977/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9000\n",
      "Epoch 978/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.0275 - accuracy: 0.9943 - val_loss: 0.1883 - val_accuracy: 0.9000\n",
      "Epoch 979/1000\n",
      "176/176 [==============================] - 0s 250us/sample - loss: 0.0383 - accuracy: 0.9943 - val_loss: 0.1868 - val_accuracy: 0.9000\n",
      "Epoch 980/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0437 - accuracy: 0.9830 - val_loss: 0.1890 - val_accuracy: 0.9000\n",
      "Epoch 981/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.1899 - val_accuracy: 0.9000\n",
      "Epoch 982/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0230 - accuracy: 0.9943 - val_loss: 0.1885 - val_accuracy: 0.9000\n",
      "Epoch 983/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.1920 - val_accuracy: 0.9000\n",
      "Epoch 984/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0245 - accuracy: 0.9943 - val_loss: 0.1891 - val_accuracy: 0.9000\n",
      "Epoch 985/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9000\n",
      "Epoch 986/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.1866 - val_accuracy: 0.9000\n",
      "Epoch 987/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.1926 - val_accuracy: 0.9000\n",
      "Epoch 988/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 0.9000\n",
      "Epoch 989/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.0245 - accuracy: 0.9943 - val_loss: 0.1957 - val_accuracy: 0.9000\n",
      "Epoch 990/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.1849 - val_accuracy: 0.9000\n",
      "Epoch 991/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0286 - accuracy: 0.9943 - val_loss: 0.1870 - val_accuracy: 0.9000\n",
      "Epoch 992/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.1870 - val_accuracy: 0.9000\n",
      "Epoch 993/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0251 - accuracy: 0.9943 - val_loss: 0.1857 - val_accuracy: 0.9000\n",
      "Epoch 994/1000\n",
      "176/176 [==============================] - 0s 227us/sample - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9000\n",
      "Epoch 995/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0228 - accuracy: 0.9943 - val_loss: 0.1869 - val_accuracy: 0.9000\n",
      "Epoch 996/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0278 - accuracy: 0.9943 - val_loss: 0.1911 - val_accuracy: 0.9000\n",
      "Epoch 997/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0256 - accuracy: 0.9943 - val_loss: 0.1874 - val_accuracy: 0.9000\n",
      "Epoch 998/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9000\n",
      "Epoch 999/1000\n",
      "176/176 [==============================] - 0s 159us/sample - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.1854 - val_accuracy: 0.9000\n",
      "Epoch 1000/1000\n",
      "176/176 [==============================] - 0s 136us/sample - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint('D2NN_ED_v1.h5',save_best_only = True)\n",
    "\n",
    "# history = model.fit(X_train.reshape([X_train.shape[0],X_train.shape[1],X_train.shape[2],1]),y_train,epochs=1000,validation_split=0.1,batch_size=64,callbacks=[checkpointer])\n",
    "history = model.fit(X_train,y_train,epochs=1000,validation_split=0.1,callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('D2NN_ED_v1.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'values')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 2ms/sample - loss: 0.0398 - accuracy: 1.0000\n",
      "test loss, test acc: [0.03981375084029943, 1.0]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate({'input1':X_test}, y_test)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict({'input1':X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 1)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "y_pred = y_pred.reshape(-1,1)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  0,  0],\n",
       "       [ 0, 31,  0],\n",
       "       [ 0,  0, 29]], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59,  1,  0],\n",
       "       [ 2, 65,  0],\n",
       "       [ 0,  0, 69]], dtype=int64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict({'input1':X_train})\n",
    "y_pred = np.argmax(y_pred,axis=1)\n",
    "y_pred = y_pred.reshape(-1,1)\n",
    "confusion_matrix(y_train,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
